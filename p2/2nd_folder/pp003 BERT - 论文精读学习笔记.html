<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<link rel="stylesheet" type="text/css" href="../../assets/markdownStyle/iconSetup.css">
	
	<!--右边底部的向上箭头，能够返回到文章最开始的地方2/2 动态效果-->
	<script type="text/javascript" src="../../assets/blogJS/wp-includes.js.jquery.jquery.js"></script>
	<script type="text/javascript" src="../../assets/blogJS/wp-content.themes.type-plus.js.main.js"></script>
	
	
	<!--https://www.dofactory.com/html/rel/icon-->
	<link rel="icon" href="../../images/ico/signature.png" sizes="32x32">
	<link rel="icon" href="../../images/ico/signature.png" sizes="192x192">
	<link rel="apple-touch-icon" href="../../images/ico/signature.png">
<link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --mermaid-theme: default; --mermaid-sequence-numbers: off; --mermaid-flowchart-curve: linear; --mermaid--gantt-left-padding: 75; --sequence-theme: simple; }


:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
h1, h2, h3, h4, h5 { white-space: pre-wrap; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; border-color: transparent !important; padding-top: 0px !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  #write > p:nth-child(1) { margin-top: 0px; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
  figure { overflow-x: visible; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; overflow-wrap: anywhere; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }


.CodeMirror { height: auto; }
.CodeMirror.cm-s-inner { background: inherit; }
.CodeMirror-scroll { overflow: auto hidden; z-index: 3; }
.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler { background-color: rgb(255, 255, 255); }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); background: inherit; white-space: nowrap; }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: rgb(0, 0, 0); }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-property { color: rgb(0, 0, 0); }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta { color: rgb(85, 85, 85); }
.cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: rgb(0, 0, 255); }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: 700; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error { color: red; }
.cm-invalidchar { color: red; }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.cm-s-inner .CodeMirror-activeline-background { background: inherit; }
.CodeMirror { position: relative; overflow: hidden; }
.CodeMirror-scroll { height: 100%; outline: 0px; position: relative; box-sizing: content-box; background: inherit; }
.CodeMirror-sizer { position: relative; }
.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar { position: absolute; z-index: 6; display: none; outline: 0px; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow: hidden; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow: auto hidden; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { position: absolute; left: 0px; top: 0px; padding-bottom: 10px; z-index: 3; overflow-y: hidden; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-wrapper { position: absolute; z-index: 4; background: 0px 0px !important; border: none !important; }
.CodeMirror-gutter-background { position: absolute; top: 0px; bottom: 0px; z-index: 4; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-radius: 0px; border-width: 0px; background: 0px 0px; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; overflow-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; }
.CodeMirror-wrap pre { overflow-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right: 30px solid transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right: none; width: auto; }
.CodeMirror-linebackground { position: absolute; inset: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; visibility: hidden; border-right: none; width: 0px; }
.CodeMirror div.CodeMirror-cursor { visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.cm-searching { background: rgba(255, 255, 0, 0.4); }
span.cm-underlined { text-decoration: underline; }
span.cm-strikethrough { text-decoration: line-through; }
.cm-tw-syntaxerror { color: rgb(255, 255, 255); background-color: rgb(153, 0, 0); }
.cm-tw-deleted { text-decoration: line-through; }
.cm-tw-header5 { font-weight: 700; }
.cm-tw-listitem:first-child { padding-left: 10px; }
.cm-tw-box { border-style: solid; border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-color: inherit; border-top-width: 0px !important; }
.cm-tw-underline { text-decoration: underline; }
@media print {
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}


:root {
    --side-bar-bg-color: #fafafa;
    --control-text-color: #777;
}

@include-when-export url(https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext);

/* open-sans-regular - latin-ext_latin */
  /* open-sans-italic - latin-ext_latin */
    /* open-sans-700 - latin-ext_latin */
    /* open-sans-700italic - latin-ext_latin */
  html {
    font-size: 16px;
    -webkit-font-smoothing: antialiased;
}

body {
    font-family: "Open Sans","Clear Sans", "Helvetica Neue", Helvetica, Arial, 'Segoe UI Emoji', sans-serif;
    color: rgb(51, 51, 51);
    line-height: 1.6;
}

#write {
    max-width: 860px;
  	margin: 0 auto;
  	padding: 30px;
    padding-bottom: 100px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1024px;
	}
}

@media only screen and (min-width: 1800px) {
	#write {
		max-width: 1200px;
	}
}

#write > ul:first-child,
#write > ol:first-child{
    margin-top: 30px;
}

a {
    color: #4183C4;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}
h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}
h1 tt,
h1 code {
    font-size: inherit;
}
h2 tt,
h2 code {
    font-size: inherit;
}
h3 tt,
h3 code {
    font-size: inherit;
}
h4 tt,
h4 code {
    font-size: inherit;
}
h5 tt,
h5 code {
    font-size: inherit;
}
h6 tt,
h6 code {
    font-size: inherit;
}
h1 {
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}
h2 {
    font-size: 1.75em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}

/*@media print {
    .typora-export h1,
    .typora-export h2 {
        border-bottom: none;
        padding-bottom: initial;
    }

    .typora-export h1::after,
    .typora-export h2::after {
        content: "";
        display: block;
        height: 100px;
        margin-top: -96px;
        border-top: 1px solid #eee;
    }
}*/

h3 {
    font-size: 1.5em;
    line-height: 1.43;
}
h4 {
    font-size: 1.25em;
}
h5 {
    font-size: 1em;
}
h6 {
   font-size: 1em;
    color: #777;
}
p,
blockquote,
ul,
ol,
dl,
table{
    margin: 0.8em 0;
}
li>ol,
li>ul {
    margin: 0 0;
}
hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

li p.first {
    display: inline-block;
}
ul,
ol {
    padding-left: 30px;
}
ul:first-child,
ol:first-child {
    margin-top: 0;
}
ul:last-child,
ol:last-child {
    margin-bottom: 0;
}
blockquote {
    border-left: 4px solid #ec962a;
    padding: 0 15px;
    color: #777777;
}
blockquote blockquote {
    padding-right: 0;
}
table {
    padding: 0;
    word-break: initial;
}
table tr {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}
table tr:nth-child(2n),
thead {
    background-color: #f8f8f8;
}
table th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    margin: 0;
    padding: 6px 13px;
}
table td {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 6px 13px;
}
table th:first-child,
table td:first-child {
    margin-top: 0;
}
table th:last-child,
table td:last-child {
    margin-bottom: 0;
}

.CodeMirror-lines {
    padding-left: 4px;
}

.code-tooltip {
    box-shadow: 0 1px 1px 0 rgba(0,28,36,.3);
    border-top: 1px solid #eef2f2;
}

.md-fences,
code,
tt {
    border: 1px solid #e7eaed;
    background-color: #f8f8f8;
    border-radius: 3px;
    padding: 0;
    padding: 2px 4px 0px 4px;
    font-size: 0.9em;
}

code {
	color: red;
    background-color: rgb(255, 255, 0)
    padding: 0 2px 0 2px;
}

.md-fences {
    margin-bottom: 15px;
    margin-top: 15px;
    padding-top: 8px;
    padding-bottom: 6px;
}


.md-task-list-item > input {
  margin-left: -1.3em;
}

@media print {
    html {
        font-size: 13px;
    }
    pre {
        page-break-inside: avoid;
        word-wrap: break-word;
    }
}

.md-fences {
	background-color: #f8f8f8;
}
#write pre.md-meta-block {
	padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
	bottom: .375rem;
}

.md-mathjax-midline {
    background: #fafafa;
}

#write>h3.md-focus:before{
	left: -1.5625rem;
	top: .375rem;
}
#write>h4.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h5.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h6.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: #a7a7a7;
    opacity: 1;
}

.md-toc { 
    margin-top:20px;
    padding-bottom:20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header, .context-menu, .megamenu-content, footer{
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state{
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

/*.html-for-mac {
    --item-hover-bg-color: #E6F0FE;
}*/

#md-notification .btn {
    border: 0;
}

.dropdown-menu .divider {
    border-color: #e5e5e5;
    opacity: 0.4;
}

.ty-preferences .window-content {
    background-color: #fafafa;
}

.ty-preferences .nav-group-item.active {
    color: white;
    background: #999;
}

.menu-item-container a.menu-style-btn {
    background-color: #f5f8fa;
    background-image: linear-gradient( 180deg , hsla(0, 0%, 100%, 0.8), hsla(0, 0%, 100%, 0)); 
}

u {
    text-decoration: red underline; 
	text-decoration-thickness: 15%;
  }
  
em {
	font-weight: bold;
    font-style: italic;
}
  


mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG2"] path[data-c], mjx-container[jax="SVG2"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}
mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
							stroke-width: 0;
						}
</style><title>pp003 BERT - 论文精读学习笔记</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><h1 id='bert---论文精读学习笔记'><span>BERT - 论文精读学习笔记</span></h1><p><span>BERT: </span><strong><span>B</span></strong><span>idirectional </span><strong><span>E</span></strong><span>ncoder </span><strong><span>R</span></strong><span>epresentations from </span><strong><span>T</span></strong><span>ransformers</span></p><div style="text-align:center; font-size:1em" >
    <a href="https://mustbook.github.io/" style="color:brown" >Cook</a>
    2024.08
</div><blockquote><p><i style="color:brown; font-family:"><span>You are what you eat.</span><br/><span>And I&#39;m cooking what I eat!  </span></i><span> </span><strong><span>:)</span></strong><span> </span></p><p><span style="color:blue; font-family:Comic Sans MS"><a href='https://mustbook.github.io/p2/2nd_paper.html'><span>More food...</span></a></span>🍜<span> </span></p></blockquote><p style="text-align:center; font-size:20px; font-weight:bold;"> 目录 </p> <div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n796"><a class="md-toc-inner" href="#bert---论文精读学习笔记">BERT - 论文精读学习笔记</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n810"><a class="md-toc-inner" href="#预备知识">预备知识</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n859"><a class="md-toc-inner" href="#梗概">梗概</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n892"><a class="md-toc-inner" href="#简介">简介</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n940"><a class="md-toc-inner" href="#摘要">摘要</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n952"><a class="md-toc-inner" href="#预训练模型pre-trained-model）">预训练模型（Pre-trained Model）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n953"><a class="md-toc-inner" href="#无监督基于特征的方法unsupervised-feature-based-approaches）">无监督基于特征的方法（Unsupervised Feature-based Approaches）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n969"><a class="md-toc-inner" href="#无监督微调方法unsupervised-fine-tuning-approaches）">无监督微调方法（Unsupervised Fine-tuning Approaches）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n987"><a class="md-toc-inner" href="#从监督数据迁移学习transfer-learning-from-supervised-data）">从监督数据迁移学习（Transfer Learning From Supervised Data）</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n993"><a class="md-toc-inner" href="#bert预训练">BERT预训练</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1055"><a class="md-toc-inner" href="#bert预训练和微调">BERT预训练和微调</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1084"><a class="md-toc-inner" href="#深入bert模型">深入BERT模型</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1125"><a class="md-toc-inner" href="#bert模型可学习参数计算">BERT模型可学习参数计算</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1131"><a class="md-toc-inner" href="#bert-输入--输出">BERT <code>输入</code> &amp; <code>输出</code></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1153"><a class="md-toc-inner" href="#切词方法wordpiece">切词方法：WordPiece</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1161"><a class="md-toc-inner" href="#合并句子的方法">合并句子的方法：</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1203"><a class="md-toc-inner" href="#mlm预训练的细节">MLM预训练的细节</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1209"><a class="md-toc-inner" href="#任务1完形填空masked-lm-mlm）">任务1：完形填空（Masked LM, MLM）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1281"><a class="md-toc-inner" href="#任务2句子匹配next-sentence-prediction-nsp）">任务2：句子匹配（Next Sentence Prediction, NSP）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1340"><a class="md-toc-inner" href="#再看微调">再看微调</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1383"><a class="md-toc-inner" href="#实验">实验</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1484"><a class="md-toc-inner" href="#ablation-studies">Ablation Studies</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1545"><a class="md-toc-inner" href="#结论和尾声">结论和尾声</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1558"><a class="md-toc-inner" href="#参考博文">参考博文</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1576"><a class="md-toc-inner" href="#博文目录">博文目录</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1578"><a class="md-toc-inner" href="#原文目录">原文目录</a></span></p></div><p><span style="color:blue; font-family:仿宋; font-weight:bold"><span>提前说明</span></span><span>：本系列博文主要是对</span><a href='#参考博文'><span>参考博文</span></a><span>的解读与重述（</span><em><span>对重点信息进行标记、或者整段摘录加深自己的记忆和理解、融合多个博文的精髓、统合不同的代表性的案例</span></em><span>），仅做学习记录笔记使用。与君共享，希望一同进步。</span></p><p>&nbsp;</p><div style="
    border-radius: 25px; 
    border: 2px solid #990000;
    background: #990000;
    padding: 20px;
"><center><span style="color:white">“自然语言处理的最大挑战之一是缺乏训练数据。因为自然语言处理是一个具有许多不同任务的多样化领域，大多数任务专用的数据集只包含几千或几十万个人工标记的培训示例。”<br/>——谷歌AI</span></center></div><p>&nbsp;</p><p><span>Bert开源仓库：</span><a href='https://github.com/google-research/bert' target='_blank' class='url'>https://github.com/google-research/bert</a></p><h3 id='预备知识'><span>预备知识</span></h3><p><img src=".\pp003_files\image-20240815120204106.png" referrerpolicy="no-referrer" alt="image-20240815120204106"></p><ul><li><p><span>浅显的语言模型：</span><span style="color:blue; font-family:Whitney"><span>Word2Vec</span></span><span> 与 </span><span style="color:blue; font-family:Whitney"><span>GloVe</span></span></p><ul><li><p><span>通过对大量无标号文本数据的预训练模型来探究学习语言表征始于</span><span style="color:blue; font-family:Whitney"><span>Word2Vec</span></span><span>与</span><span style="color:blue; font-family:Whitney"><span>GloVe</span></span><span>中</span><span style="border-bottom: 2px dashed FireBrick;"><span>词的嵌入</span></span><span>。</span><sup><span>词嵌入的由来吗？</span></sup><span>这些嵌入改变了自然语言处理任务的执行方式。现在的嵌入</span><span style="color:red"><span>可以捕捉词之间的上下文关系</span></span><span>。</span></p></li><li><p><span>这些嵌入用于训练自然语言处理下游任务的模型，做出更好的预测。即使使用较少的任务专用的数据，也可以通过利用嵌入本身的附加信息来实现这一点。</span></p></li></ul></li><li><p><span>更深入、复杂的语言模型：</span><span style="color:blue; font-family:Whitney"><span>LSTM</span></span><span>和</span><span style="color:blue; font-family:Whitney"><span>GRU层</span></span></p><ul><li><p><span>这些嵌入的局限性在于他们使用了非常浅显的语言模型。这意味着他们</span><mark style="background:#f8e272;"><span>能够捕获的信息量有限</span></mark><span>，这促使人们使用更深入、更复杂的语言模型（LSTM和GRU层）。</span></p></li><li><p><span>另一个关键的</span><mark style="background:#f8e272;"><span>制约因素</span></mark><span>是：这些模式没有考虑到该词的上下文。以上面的“bank”为例，同一个词在不同的语境中有不同的含义。然而，像Word2Vec这样的嵌入将在上下文中为“bank”提供相同的向量。</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>这一宝贵信息不应被忽视</span></span></p></li></ul></li><li><p><span>输入</span><span style="color:blue; font-family:Whitney"><span>ELMo</span></span><span>与</span><span style="color:blue; font-family:Whitney"><span>ULMFiT</span></span><span>：</span></p><ul><li><p><span>自然语言处理社区用</span><span style="color:blue; font-family:Whitney"><span>ELMo</span></span><span>处理多义词，多义词指一个词由于上下文不同，含义也不同。从训练浅层前馈网络（Word2Vec），到逐步使用复杂的双向LSTM体系结构层来训练词嵌入。这意味着同一个单词可以基于其上下文具有多个</span><span style="color:blue; font-family:Whitney"><span>ELMo</span></span><span>嵌入。</span></p><p><span>从那时起，预训练就成为了自然语言处理的一种培训机制。</span></p></li><li><p><span style="color:blue; font-family:Whitney"><span>ULMFiT</span></span><span>在这一点做得更深入。该框架</span><span style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>可以</span></span><span style="color:red"><span>训练可调的语言模型</span></span><span>，即使在各种文档分类任务上的数据较少（少于100个示例）的情况下，也可以提供出色的结果。可以肯定地说，</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>ULMFiT破解了自然语言处理中迁移学习的秘密</span></span><span>。</span></p><p><span>这就是在自然语言处理中的</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>迁移学习</span></span><span>的</span><kbd style="background:yellow; color:red"><span>黄金公式</span></kbd><span>：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n837" cid="n837" mdtype="math_block" data-math-tag-before="0" data-math-tag-after="1" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 46.952ex; position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="2.262ex" role="img" focusable="false" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.566ex; min-width: 46.952ex;"><defs><path id="MJX-829-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-829-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-829-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-829-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-829-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.019382,-0.019382) translate(0, -750)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 750) matrix(1 0 0 -1 0 0) scale(51.6)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="8298.4 -750 1 1000"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr"><g data-mml-node="mtd"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">自</text></g><g data-mml-node="mtext" transform="translate(825.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">然</text></g><g data-mml-node="mtext" transform="translate(1651.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">语</text></g><g data-mml-node="mtext" transform="translate(2477.8,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">言</text></g><g data-mml-node="mtext" transform="translate(3303.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">处</text></g><g data-mml-node="mtext" transform="translate(4129.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">理</text></g><g data-mml-node="mtext" transform="translate(4955.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">中</text></g><g data-mml-node="mtext" transform="translate(5781.5,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">的</text></g><g data-mml-node="mtext" transform="translate(6607.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">迁</text></g><g data-mml-node="mtext" transform="translate(7433.3,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">移</text></g><g data-mml-node="mtext" transform="translate(8259.3,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">学</text></g><g data-mml-node="mtext" transform="translate(9085.2,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">习</text></g><g data-mml-node="mo" transform="translate(10188.9,0)"><use data-c="3D" xlink:href="#MJX-829-TEX-N-3D"></use></g><g data-mml-node="mtext" transform="translate(11244.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">预</text></g><g data-mml-node="mtext" transform="translate(12070.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">训</text></g><g data-mml-node="mtext" transform="translate(12896.5,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">练</text></g><g data-mml-node="mo" transform="translate(13944.7,0)"><use data-c="2B" xlink:href="#MJX-829-TEX-N-2B"></use></g><g data-mml-node="mtext" transform="translate(14944.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">微</text></g><g data-mml-node="mtext" transform="translate(15770.8,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="825.5px" font-family="serif">调</text></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -750 1 1000"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:1"><g data-mml-node="mtext"><use data-c="28" xlink:href="#MJX-829-TEX-N-28"></use><use data-c="31" xlink:href="#MJX-829-TEX-N-31" transform="translate(389,0)"></use><use data-c="29" xlink:href="#MJX-829-TEX-N-29" transform="translate(889,0)"></use></g></g></g></svg></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(1)</mtext></mtd><mtd><mtext>自</mtext><mtext>然</mtext><mtext>语</mtext><mtext>言</mtext><mtext>处</mtext><mtext>理</mtext><mtext>中</mtext><mtext>的</mtext><mtext>迁</mtext><mtext>移</mtext><mtext>学</mtext><mtext>习</mtext><mo>=</mo><mtext>预</mtext><mtext>训</mtext><mtext>练</mtext><mo>+</mo><mtext>微</mtext><mtext>调</mtext></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></div></div><p><span style="color:blue; font-family:Whitney"><span>ULMFiT</span></span><span>之后，大多数自然语言处理突破上述公式的要素，并取得了最新的基准。</span></p></li></ul></li><li><p><span>OpenAI的</span><span style="color:blue; font-family:Whitney"><span>GPT</span></span></p><ul><li><p><span>OpenAI的GPT</span><span style="color:red"><span>扩展了</span><span style="color:blue; font-family:Whitney"><span>ULMFiT</span></span><span>和</span><span style="color:blue; font-family:Whitney"><span>ELMo</span></span><span>带来的预训练和微调法</span></span><span>。GPT本质上是用基于Transformer的体系结构代替了基于LSTM的语言建模体系结构。</span></p></li><li><p><span>GPT模型可以微调到</span><span style="color:red"><span>超出文档分类的多个自然语言处理任务</span></span><span>，例如</span><kbd><span>常识推理</span></kbd><span>、</span><kbd><span>语义相似度</span></kbd><span>和</span><kbd><span>阅读理解</span></kbd><span>。</span></p></li><li><p><span>GPT还强调了Transformer框架的重要性，该框架具有更简单的体系结构，</span><span style="border-bottom: 2px dashed FireBrick;"><span>其训练速度比基于LSTM的模型更快，还能够通过使用注意力机制来学习数据中复杂模式</span></span><span>。</span></p></li><li><p><span>OpenAI的GPT通过实现多种先进技术证实了Transformer框架的强大和实用性。</span></p></li></ul><p><span>这就是Transformer如何促成了BERT的开发，以及自然语言处理中的后续所有突破。</span></p></li></ul><div class="md-diagram-panel md-fences-adv-panel"><svg id="mermaidChart85" width="100%" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style="max-width: 1221.875px;" viewBox="-7.5 -8 1221.875 222.78125" role="graphics-document document" aria-roledescription="flowchart-v2"><style>#mermaidChart85{font-family:sans-serif;font-size:16px;fill:#333;}#mermaidChart85 .error-icon{fill:#552222;}#mermaidChart85 .error-text{fill:#552222;stroke:#552222;}#mermaidChart85 .edge-thickness-normal{stroke-width:2px;}#mermaidChart85 .edge-thickness-thick{stroke-width:3.5px;}#mermaidChart85 .edge-pattern-solid{stroke-dasharray:0;}#mermaidChart85 .edge-pattern-dashed{stroke-dasharray:3;}#mermaidChart85 .edge-pattern-dotted{stroke-dasharray:2;}#mermaidChart85 .marker{fill:#333333;stroke:#333333;}#mermaidChart85 .marker.cross{stroke:#333333;}#mermaidChart85 svg{font-family:sans-serif;font-size:16px;}#mermaidChart85 .label{font-family:sans-serif;color:#333;}#mermaidChart85 .cluster-label text{fill:#333;}#mermaidChart85 .cluster-label span,#mermaidChart85 p{color:#333;}#mermaidChart85 .label text,#mermaidChart85 span,#mermaidChart85 p{fill:#333;color:#333;}#mermaidChart85 .node rect,#mermaidChart85 .node circle,#mermaidChart85 .node ellipse,#mermaidChart85 .node polygon,#mermaidChart85 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaidChart85 .flowchart-label text{text-anchor:middle;}#mermaidChart85 .node .label{text-align:center;}#mermaidChart85 .node.clickable{cursor:pointer;}#mermaidChart85 .arrowheadPath{fill:#333333;}#mermaidChart85 .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaidChart85 .flowchart-link{stroke:#333333;fill:none;}#mermaidChart85 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaidChart85 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaidChart85 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaidChart85 .cluster text{fill:#333;}#mermaidChart85 .cluster span,#mermaidChart85 p{color:#333;}#mermaidChart85 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaidChart85 .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaidChart85 :root{--mermaid-alt-font-family:sans-serif;}</style><g><marker id="flowchart-pointEnd" class="marker flowchart" viewBox="0 0 12 20" refX="10" refY="5" markerUnits="userSpaceOnUse" markerWidth="12" markerHeight="12" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" class="arrowMarkerPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker><marker id="flowchart-pointStart" class="marker flowchart" viewBox="0 0 10 10" refX="0" refY="5" markerUnits="userSpaceOnUse" markerWidth="12" markerHeight="12" orient="auto"><path d="M 0 5 L 10 10 L 10 0 z" class="arrowMarkerPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker><marker id="flowchart-circleEnd" class="marker flowchart" viewBox="0 0 10 10" refX="11" refY="5" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><circle cx="5" cy="5" r="5" class="arrowMarkerPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></circle></marker><marker id="flowchart-circleStart" class="marker flowchart" viewBox="0 0 10 10" refX="-1" refY="5" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><circle cx="5" cy="5" r="5" class="arrowMarkerPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></circle></marker><marker id="flowchart-crossEnd" class="marker cross flowchart" viewBox="0 0 11 11" refX="12" refY="5.2" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><path d="M 1,1 l 9,9 M 10,1 l -9,9" class="arrowMarkerPath" style="stroke-width: 2; stroke-dasharray: 1, 0;"></path></marker><marker id="flowchart-crossStart" class="marker cross flowchart" viewBox="0 0 11 11" refX="-1" refY="5.2" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><path d="M 1,1 l 9,9 M 10,1 l -9,9" class="arrowMarkerPath" style="stroke-width: 2; stroke-dasharray: 1, 0;"></path></marker><g class="root"><g class="clusters"></g><g class="edgePaths"></g><g class="edgeLabels"></g><g class="nodes"><g class="root" transform="translate(79.703125, -5.203125)"><g class="clusters"><g class="cluster default flowchart-label" id="subGraph3"><rect style="" rx="0" ry="0" x="-79.203125" y="8" width="317.78125" height="201.1875"></rect><g class="cluster-label" transform="translate(-79.203125, 8)"><foreignObject width="317.78125" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">非常浅显的语言模型：词嵌入 | <span style="color:red">浅层前馈网络</span></span></div></foreignObject></g></g></g><g class="edgePaths"></g><g class="edgeLabels"></g><g class="nodes"><g class="node default default flowchart-label" id="flowchart-id1-2068" transform="translate(79.6875, 63.296875)"><rect class="basic label-container" style="" rx="5" ry="5" x="-46.6875" y="-20.296875" width="93.375" height="40.59375"></rect><g class="label" style="" transform="translate(-39.1875, -12.796875)"><rect></rect><foreignObject width="78.375" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">Word2Vec</span></div></foreignObject></g></g><g class="node default default flowchart-label" id="flowchart-id2-2069" transform="translate(79.6875, 153.890625)"><rect class="basic label-container" style="" rx="5" ry="5" x="-30.0703125" y="-20.296875" width="60.140625" height="40.59375"></rect><g class="label" style="" transform="translate(-22.5703125, -12.796875)"><rect></rect><foreignObject width="45.140625" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">GloVe</span></div></foreignObject></g></g></g></g><g class="root" transform="translate(390.6328125, -5.203125)"><g class="clusters"><g class="cluster default flowchart-label" id="更深入、复杂的语言模型"><rect style="" rx="0" ry="0" x="-22.3515625" y="8" width="176" height="201.1875"></rect><g class="cluster-label" transform="translate(-22.3515625, 8)"><foreignObject width="176" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">更深入、复杂的语言模型</span></div></foreignObject></g></g></g><g class="edgePaths"></g><g class="edgeLabels"></g><g class="nodes"><g class="node default default flowchart-label" id="flowchart-id3-2066" transform="translate(65.6484375, 63.296875)"><rect class="basic label-container" style="" rx="5" ry="5" x="-28.625" y="-20.296875" width="57.25" height="40.59375"></rect><g class="label" style="" transform="translate(-21.125, -12.796875)"><rect></rect><foreignObject width="42.25" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">LSTM</span></div></foreignObject></g></g><g class="node default default flowchart-label" id="flowchart-id4-2067" transform="translate(65.6484375, 153.890625)"><rect class="basic label-container" style="" rx="5" ry="5" x="-32.6484375" y="-20.296875" width="65.296875" height="40.59375"></rect><g class="label" style="" transform="translate(-25.1484375, -12.796875)"><rect></rect><foreignObject width="50.296875" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">GRU层</span></div></foreignObject></g></g></g></g><g class="root" transform="translate(654.34375, -5.203125)"><g class="clusters"><g class="cluster default flowchart-label" id="subGraph1"><rect style="" rx="0" ry="0" x="-60.0625" y="8" width="258.84375" height="201.1875"></rect><g class="cluster-label" transform="translate(-60.0625, 8)"><foreignObject width="258.84375" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">ELMo | <span style="color:red">复杂的双向LSTM体系结构层</span></span></div></foreignObject></g></g></g><g class="edgePaths"></g><g class="edgeLabels"></g><g class="nodes"><g class="node default default flowchart-label" id="flowchart-id5-2064" transform="translate(69.359375, 63.296875)"><rect class="basic label-container" style="" rx="5" ry="5" x="-28.90625" y="-20.296875" width="57.8125" height="40.59375"></rect><g class="label" style="" transform="translate(-21.40625, -12.796875)"><rect></rect><foreignObject width="42.8125" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">ELMo</span></div></foreignObject></g></g><g class="node default default flowchart-label" id="flowchart-id6-2065" transform="translate(69.359375, 153.890625)"><rect class="basic label-container" style="" rx="5" ry="5" x="-36.359375" y="-20.296875" width="72.71875" height="40.59375"></rect><g class="label" style="" transform="translate(-28.859375, -12.796875)"><rect></rect><foreignObject width="57.71875" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">ULMFiT</span></div></foreignObject></g></g></g></g><g class="root" transform="translate(895.125, -8)"><g class="clusters"><g class="cluster default flowchart-label" id="OpenAI的GPT"><rect style="" rx="0" ry="0" x="8" y="8" width="303.25" height="206.78125"></rect><g class="cluster-label" transform="translate(107.1171875, 8)"><foreignObject width="105.015625" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">OpenAI的GPT</span></div></foreignObject></g></g></g><g class="edgePaths"><path d="M159.625,73.59375L159.625,111.390625L159.625,149.1875" id="L-id8-id7-0" class=" edge-thickness-normal edge-pattern-solid flowchart-link LS-id8 LE-id7" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path></g><g class="edgeLabels"><g class="edgeLabel" transform="translate(159.625, 111.390625)"><g class="label" transform="translate(-16, -12.796875)"><foreignObject width="32" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="edgeLabel">代替</span></div></foreignObject></g></g></g><g class="nodes"><g class="node default default flowchart-label" id="flowchart-id7-2060" transform="translate(159.625, 169.484375)"><rect class="basic label-container" style="" rx="5" ry="5" x="-116.625" y="-20.296875" width="233.25" height="40.59375"></rect><g class="label" style="" transform="translate(-109.125, -12.796875)"><rect></rect><foreignObject width="218.25" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">基于LSTM的语言建模体系结构</span></div></foreignObject></g></g><g class="node default default flowchart-label" id="flowchart-id8-2061" transform="translate(159.625, 53.296875)"><rect class="basic label-container" style="" rx="5" ry="5" x="-109.4375" y="-20.296875" width="218.875" height="40.59375"></rect><g class="label" style="" transform="translate(-101.9375, -12.796875)"><rect></rect><foreignObject width="203.875" height="25.59375"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span class="nodeLabel">基于Transformer的体系结构</span></div></foreignObject></g></g></g></g></g></g></g></svg></div><ul><li><p><span>因此，解决自然语言处理任务的新方法可以简化为两步</span></p><p><kbd style="background:#f8e272"><span>1</span></kbd><span> 在大型无标号文本语料库（可以是无监督或半监督）中训练语言模型；</span></p><p><kbd style="background:#a8e195"><span>2</span></kbd><span> 根据具体的自然语言处理任务对此大型模型进行微调，以利用此模型获得的大型知识库（有监督）。</span></p></li></ul><center>	<span style="color:red; font-family:仿宋; font-weight:bold">背景结束</span> <hr style="border-bottom: dashed 1px red; width:70%"></center><p>&nbsp;</p><h3 id='梗概'><span>梗概</span></h3><p><kbd style="background:#f8e272"><span>1</span></kbd><span> </span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span></p><p><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>就是，事先在一个较大的数据集上面训练好一个模型的这次训练过程（在这之后，再把这个模型拿到别的任务上面继续训练）。</span></p><p><span>BERT是一种</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练模型</span></span><span>，通过对大量语料库进行训练，学习了</span><span style="color:red"><span>语言特征</span></span><span>和</span><span style="color:red"><span>语法规则</span></span><span>，从而具备了理解自然语言的能力。</span></p><p><span>通过</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>的语言模型可有效地提升多数下游任务，处理下游任务（迁移学习）的方法大致分为</span><span style="color:red"><span>2种</span></span><span>：</span></p><ul><li><p><span>feature-based(feature-extraction)</span></p><ul><li><p><span>例如，</span><span style="color:#b000e0;font-weight:bold"><span>ELMo</span></span><span>，使用task-specific architectures，包括预训练的表征作为额外的特征；</span></p></li></ul></li><li><p><span>fine-tuning</span></p><ul><li><p><span>例如，</span><span style="color:#b000e0;font-weight:bold"><span>the Generative Pre-trained Transformer(OpenAI GPT)</span></span><span>，是训练在下游任务上的，通过简单的微调所有预训练的参数。</span></p></li></ul></li></ul><p><kbd style="background:#a8e195"><span>2</span></kbd><span> BERT的特色功能——论文解读</span></p><p><strong style="color:red"><span>※</span></strong><span> 论文解读：通过分析论文的内容和结构，理解其主旨、观点、论证方法等，从而为后续研究或应用提供参考。</span></p><p><strong style="color:red"><span>※</span></strong><span> 主题分类：利用BERT对论文主题进行分类，可以有效地将论文归类到相应的领域或研究方向。</span></p><p><strong style="color:red"><span>※</span></strong><span> 情感分析：通过BERT可以分析论文中的情感倾向，有助于研究人员了解论文作者的态度和观点。</span></p><p><strong style="color:red"><span>※</span></strong><span> 摘要生成：BERT可以用于自动生成论文的摘要，从而帮助读者快速了解论文的核心内容。</span></p><p><strong style="color:red"><span>※</span></strong><span> 实体识别：BERT可以识别论文中的实体名词，如人名、地名、机构名等，有助于进一步的信息提取和知识图谱构建。</span></p><p><strong style="color:red"><span>※</span></strong><span> 指代消解：BERT可以帮助确定论文中的代词指代对象，提高文本的可读性和理解性。</span></p><p><kbd style="background:#a5c4ff"><span>3</span></kbd><span> BERT技术原理</span></p><p><span>基于Transformer架构，通过预训练语言模型来学习语言的特征表示。</span></p><ul><li><p><span>具体来说，BERT</span><span style="color:red"><span>首先</span></span><span>对大量语料库进行预训练，在这个过程中，一些单词会被随机遮盖住，</span><span style="color:red"><span>然后</span></span><span>模型需要填充这些被遮盖的单词，这个过程有助于模型更好地关注上下文信息。</span></p></li><li><p><span style="color:red"><span>此外</span></span><span>，BERT还采用了双向编码结构，同时考虑了文本的顺序和逆序，以便更全面地捕捉上下文信息。</span><span style="color:red"><span>在训练完成后</span></span><span>，BERT可以应用于各种NLP任务，如文本分类、情感分析、摘要生成等。</span></p></li></ul><p><span>实验结果：</span></p><div style="
    border-radius: 25px; 
    border: 2px solid #990000;
    padding: 20px;
">&nbsp; &nbsp; &nbsp; &nbsp; 在论文解读领域，BERT的实验结果已经展现了强大的实力。<br/>&nbsp; &nbsp; &nbsp; &nbsp; <strong style="color:red">✔</strong> 通过应用BERT进行<span style="color:red">主题分类和情感分析</span>，研究人员可以更快速地理解论文的内容和作者的观点。<br/>&nbsp; &nbsp; &nbsp; &nbsp; <strong style="color:red">✔</strong> 此外，BERT还可以<span style="color:red">自动生成论文的摘要</span>，从而减轻读者的阅读负担。<br/>&nbsp; &nbsp; &nbsp; &nbsp; <strong style="color:red">✖</strong> 然而，BERT也存在一些不足之处，例如对于一些专业领域的术语和词汇理解不够准确，需要进一步改进和优化。</div><h3 id='简介'><span>简介</span></h3><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>什么是Bert？</span></span><span> </span></p><p><span>是一个</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>的语言表征模型，是一个</span><strong><span>深度的、双向的Transformer</span></strong><span>，用来做</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>，针对一般的语言理解任务。</span></p><p><span>是一个自然语言处理框架</span><sup><span>博文1</span></sup><span>。可以毫不夸张地说，BERT已经对自然语言处理进行了显著的变革。比如</span><span style="color:red"><span>使用一个在大型无标号数据集上训练的模型，在11个独立的自然语言处理任务中取得佳绩。只需稍加微调就能实现</span></span><span>。</span></p><p><span>BERT是一个“</span><span style="color:red"><span>深度双向</span></span><span>”的模型。双向意味着BERT在训练阶段从所选文本的</span><span style="border-bottom: 2px dashed FireBrick;"><span>左右上下文中</span></span><span>汲取信息。</span></p><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>实例</span></kbd><span> 有两句话，都涉及“bank”一词。</span></p><p><img src=".\pp003_files\image-20240815115449691.png" referrerpolicy="no-referrer" alt="image-20240815115449691"></p><ul><li><p><span>BERT同时捕获</span><span style="border-radius: 10px; border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>左右上下文</span></span><span>。</span></p></li><li><p><span>如果仅取</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>左上下文</span></span><span>或</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>右上下文</span></span><span>来预测单词“bank”的性质，那么在两个给定示例中，至少有一个会出错。 </span></p><ul><li><p><span>解决这个问题的一个方法是，在做出预测之前同时考虑</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>左上下文</span></span><span>和</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>右上下文</span></span><span>。</span></p></li></ul></li></ul><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>Bert名称由来</span></span><span> </span></p><p><span>B=Bidirectional, E=Encoder, R=Representations, T=Transformers</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>Bert的目的</span></span><span> </span></p><p><span>通过</span><span style="color:red"><span>在所有层中</span></span><span>对</span><span style="border-bottom: 2px dashed FireBrick;"><span>左右上下文</span></span><span>进行联合条件反射，从未标记的文本中</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>深度双向表示。</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>优势</span></span><span> —— 普适性</span></p><p><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>的BERT模型可以通过</span><span style="color:red"><span>一个额外的输出层</span></span><span>进行微调，从而应用于更多样的任务，如问答和语言推理，并且无需对特定的任务架构进行大量的修改。</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>BERT的意义</span></span><span> </span></p><p><span>让我们能够</span><span style="color:red"><span>从一个大数据集上</span></span><span>训练好</span><span style="color:red"><span>一个比较深的神经网络</span></span><span>，用于很多不同的NLP任务上面，既简化了训练，又提升了性能。</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>与其他工作的关系</span></span><span> </span></p><p><span style="color:blue; font-family:Whitney"><span>ELMo</span></span><span>试图在</span><span style="color:red"><span>从左到右</span></span><span>和</span><span style="color:red"><span>从右到左</span></span><span>的上下文中训练两个</span><strong><span>LSTM</span></strong><span>语言模型，并将它们简单连接起来，解决这个问题。</span><span style="border-bottom: 2px dashed FireBrick;"><span>尽管它大大改进了现有技术，但还不够</span></span><span>。</span></p><div style="
    border-radius: 25px; 
    border: 2px solid #990000;
    background: #990000;
    padding: 20px;
"><center><span style="color:white">“直观来说，人们有理由相信，深度双向模型比从左到右模型或从左到右和从右到左模型的简单连接更强大。” <br/>——BERT</span></center></div><p><span>Bert工作是基于</span><span style="color:blue; font-family:Whitney"><span>GPT</span></span><span>和</span><span style="color:blue; font-family:Whitney"><span>EMLo</span></span><span>这两个工作的。</span></p><p><img src=".\pp003_files\image-20240813110254743.png" referrerpolicy="no-referrer" alt="image-20240813110254743"></p><blockquote><ul><li><p><span>箭头表示从一层到下一层的信息流。</span></p></li><li><p><span>顶部的</span><span style="color:#00b456"><span>绿色框</span></span><span>表示每个输入词的</span><span style="border-bottom: 2px dashed FireBrick;"><span>最终上下文化表示</span></span><span>。</span></p></li></ul><p><span style="color:blue"><span>从上面的图像可以看出：</span><strong><span>BERT是双向的</span></strong><span>，</span><strong><span>GPT是单向的</span></strong><span>（信息只从左到右流动），</span><strong><span>ELMo是浅双向的</span></strong><span>。 </span></span><span> </span></p><center>这就是Masked Language Model在图像中的表示。 </center></blockquote><p><span style="color:red"><span>单向的标准语言模型</span></span><span>，很大程度限制了预训练模型表示能力的学习。</span></p><p><span style="color:blue"><span>OpenAI GPT</span></span><span>使用</span><span style="border-bottom: 2px dashed FireBrick;"><span>从左到右</span></span><span>的架构，</span><span style="color:blue"><span>Transformer</span></span><span>的self-Attenton层的每一个token仅依赖于之前的tokens（训练任务结束），</span><span style="color:blue"><span>这种架构</span></span><span>预训练的语言模型</span><span style="color:red"><span>很难处理句子层级的下游任务</span></span><span>，如Question-Answer(QA)，因为Answer往往和Question的上下文有关。</span></p><p><kbd style="background:yellow; color:red"><span>问题</span></kbd><span> </span><strong><span>为什么语言生成模型是单向的？</span></strong><span> </span></p><p><kbd style="background:yellow; color:red"><span>答案</span></kbd><span> </span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: pink"><span>语言生成模型能够基于部分单词序列，生成下一个单词的概率分布，这种性质决定语言生成模型是单向模型</span></span><span>。语言模型适合做</span><span style="border-bottom: 2px dashed FireBrick;"><span>生成任务</span></span><span>，如单向语言模型GPT（生成模型）的文本生成能力很强。</span></p><p><span>BERT使用双向编码器中，</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>单词可以看到其自身，通过上下文单词信息“填空”</span></span><span>，BERT不是</span><span style="text-decoration: underline 1px solid red; text-decoration-style: double"><span>语言生成模型</span></span><span>，可看作为</span><span style="border-bottom: 2px dotted FireBrick;"><span>语言理解模型</span></span><span>，但这种模型不适合做生成任务，适合做</span><span style="color:red"><span>利用上下文信息的标注和分类</span></span><span>任务！</span></p><p><span>BERT预训练语言模型的特点：</span></p><ul><li><p><span style="color:red"><span>基于掩盖的方式</span></span><span>预训练双向语言模型，可以使用更深的网络架构；</span></p></li><li><p><span style="color:#990000"><span>基于fine-tuning处理下游任务</span></span><span>，同时在sentence-level和token-level的多数任务中均达到出色的表现。</span></p></li></ul><p>&nbsp;</p><h3 id='摘要'><span>摘要</span></h3><p><span>BERT (</span><strong><span>B</span></strong><span>idirectional </span><strong><span>E</span></strong><span>ncoder </span><strong><span>R</span></strong><span>epresentations from </span><strong><span>T</span></strong><span>ransformers) 在未标记的文本上进行预训练，调节各个层的参数，学习上下文表示。因此</span><span style="color:red"><span>只需要增加一个输出层</span></span><span>进行</span><strong><span>微调</span></strong><span>，就能在多个任务上达到 SOTA 水平。</span></p><p><span>BERT贡献：</span></p><ul><li><p><span>证明了双向预训练对于语言表示模型的重要性</span></p></li><li><p><span>减少了为特定任务精心设计网络架构的必要性</span></p><p>❗️<span> </span><span style="color:red"><span>这个是挺秀的，不用为了</span><span style="color:blue"><span>特定任务</span></span><span>专门精心设计</span><span style="color:blue"><span>网络架构</span></span></span><span>。</span></p></li><li><p><span>BERT在11个NLP任务上达到了SOTA水平</span></p></li></ul><p>&nbsp;</p><h3 id='预训练模型pre-trained-model）'><span>预训练模型（Pre-trained Model）</span></h3><h4 id='无监督基于特征的方法unsupervised-feature-based-approaches）'><span>无监督基于特征的方法（Unsupervised Feature-based Approaches）</span></h4><p><span>嵌入表达是NLP领域的重要组成部分，如</span><span style="color:red"><span>词嵌入</span></span><span>、</span><span style="color:red"><span>句嵌入</span></span><span>、</span><span style="color:red"><span>篇章嵌入</span></span><span>等。对于</span><span style="color:red"><span>句嵌入</span></span><span>，常用的训练方法包括：</span></p><ul><li><p><span>给定前一句表示，从左到右依次生成下一句；</span></p></li><li><p><span>auto-encoder方法。</span></p></li></ul><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>BERT与</span><span style="color:#b000e0;font-weight:bold"><span>ELMo</span></span><span>的区别</span></span><span>：</span></p><ul><li><p><span style="color:#b000e0;font-weight:bold"><span>ELMo</span></span><span>用的是</span><span style="border-bottom: 2px dashed FireBrick;"><span>基于RNN的架构</span></span><span>，在用于一些特定的下游任务时，需要对架构做一定的调整；</span></p><ul><li><p><span style="color:#b000e0;font-weight:bold"><span>ELMo</span></span><span>通过双向网络提取具有上下文信息的词嵌入（拼接前后向词嵌入），在多数NLP任务取得非常好的表现，如QA、情感分析、NER等。</span></p></li></ul></li><li><p><span>BERT用的是</span><span style="border-bottom: 2px dashed FireBrick;"><span>Transformer</span></span><span>，只需要改最上层的就行了，这里指的是BERT的那个</span><span style="color:red"><span>额外的输出层</span></span><span>。</span></p></li></ul><h4 id='无监督微调方法unsupervised-fine-tuning-approaches）'><span>无监督微调方法（Unsupervised Fine-tuning Approaches）</span></h4><p><span>最近利用无标签数据预训练的句子和篇章编码器，可生成具有上下文信息的</span><span style="color:red"><span>词嵌入</span></span><span>用于下游监督任务，</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: pink"><span>这种方法的好处</span></span><span>是</span><span style="border-bottom: 2px dashed FireBrick;"><span>下游任务从头开始学的参数较少</span></span><span>。</span></p><p><span>OpenAI GPT在句子级别的任务中达到很好的效果，这种模型一般</span><span style="color:red"><span>利用单向RNN网络</span></span><span>或</span><span style="color:red"><span>auto-encoder</span></span><span>预训练。</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>BERT与GPT的区别</span></span><span>：</span></p><ul><li><p><span>在2018年，GPT是单向的，基于左边的上下文信息，来生成新的文段；</span></p></li><li><p><span>而Bert不仅用了左侧的信息，还用了右侧的信息，所以说是一个双向的操作，即Bidirectional。</span></p><p><span>BERT采用双向编码器结构，这意味着它同时考虑了文本的</span><span style="color:red"><span>顺序和逆序</span></span><span>，能够</span><span style="border-bottom: 2px dashed FireBrick;"><span>更全面地捕捉上下文信息</span></span><span>。</span></p><blockquote><p><span>bidirectional </span><code>美/ ˌbaɪdəˈrekʃənl; ˌbaɪdaɪˈrekʃənl /</code></p><ul><li><p><em><span>adj.</span></em><span>双向的；双向作用的</span></p></li></ul><blockquote><p><span>The mapping can be unidirectional or </span><strong><span>bidirectional</span></strong><span>.</span></p><p><span>映射可以是单向的或者双向的。</span></p></blockquote></blockquote></li></ul><h4 id='从监督数据迁移学习transfer-learning-from-supervised-data）'><span>从监督数据迁移学习（Transfer Learning From Supervised Data）</span></h4><blockquote><p><span>大规模标注数据（预训练） → 小规模标注集的类似任务（微调）</span></p></blockquote><p><span>利用</span><span style="color:red"><span>大规模标注数据</span></span><span>预训练，在</span><span style="color:red"><span>小规模标注集的类似任务</span></span><span>微调，也能得到较好的效果，比如自然语言推理、机器翻译等。翻译模型可在不同语言间迁移，模型能够学习到语言的羽凡等特征表示。</span></p><p><span>CV领域也有类似处理，如在ImageNet数据集预训练，具体下游任务fine-tuning。</span></p><p>&nbsp;</p><h3 id='bert预训练'><span>BERT预训练</span></h3><ul><li><p><span>预训练在NLP的应用</span></p><ul><li><p><span style="color:blue"><span>句子层面</span></span><span>的任务：通过整体分析来预测句子之间的关系，如，</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>对句子情绪的识别，或者两个句子之间的关系</span></span><span>；</span></p></li><li><p><span style="color:blue"><span>词语层面</span></span><span>的任务：标记级任务，如命名实体识别和问答（</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>比如“张三”这个词是不是人名？还是一种食物？</span></span><span>）</span></p></li></ul><p><span>事实上，预训练在计算机视觉领域已经用了很多年了，BERT也不是自然语言处理领域第一个用预训练的，只是说，因为BERT效果太好了，以至于</span><strong><span>抢了风头</span></strong><span>。</span></p><p><span>预训练的表示，</span><span style="border-bottom: 2px dotted FireBrick;"><span>减少了</span></span><span>对许多高度工程化的任务的</span><span style="border-bottom: 2px dotted FireBrick;"><span>特定架构的需求</span></span><span>。</span></p><p><span>BERT是第一个</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>基于调优</span></span><span>的表示模型，在大量句子级和记号级的任务上实现了最先进的性能，甚至优于很多特定于某种任务的架构。</span></p></li><li><p><span>NLP中</span><code>2种</code><span>预训练的策略</span></p><ul><li><p><span>将语言模型预训练应用于下游任务中，或者说特征表示，有两种现成的策略：</span><span style="text-decoration: underline 1px solid red; text-decoration-style: double"><span>基于特征、基于微调</span></span><span>。</span></p><ul><li><p><span style="color:#00b456"><span>基于特征</span></span><span>（feature-based）：如</span><span style="color:blue; font-family:Whitney"><span>ELMo</span></span><span> —— 使用特定于任务的RNN架构，把学到的特征和输入一起作为特征的表达。</span></p></li><li><p><span style="color:#00b456"><span>基于微调</span></span><span>（fine-tuning）：如</span><span style="color:blue; font-family:Whitney"><span>GPT</span></span><span> —— 引入了最小的任务特定参数，并通过简单的一点点微调所有预训练参数，来对下游任务进行训练。</span></p><p><span>（</span><span style="color:red"><span>GPT选择从左到右的架构，这使得每个token只能注意到它前面的token，这对sentence级的任务影响还是</span><strong><span>次要的</span></strong><span>，但</span><span style="border-bottom: 2px dashed FireBrick;"><span>对于token级的任务</span></span><span>来说影响</span><strong><span>就很巨大</span></strong><span>。</span></span><span>）</span></p></li></ul><p><span>在当时，这些的技术限制了预训练表征的力量，</span><span style="color:#b000e0;font-weight:bold"><span>主要是因为</span></span><span style="border-bottom: 2px dashed FireBrick;"><span>标准语言模型是</span><strong style="color:red"><span>单向的</span></strong></span><span>。</span></p><ul><li><p><span>传统的单向语言模型，或者是浅层拼接两个单向语言模型，只能获取单方向的上下文信息。</span></p></li><li><p><span>标准的语言模型只能实现从左到右或从右到左的训练，不能实现真正的双向训练，这是因为</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>双向的条件</span></span><span>是</span><span style="border-bottom: 2px dotted FireBrick;"><span>每个单词能直接“看到自己”，并且模型可以在多层上下文中轻松的预测出目标词</span></span><span>。</span></p></li></ul><p><span>如果要获取句子层面，或者说句子之间的信息的话，就显得有些吃力了。</span></p></li></ul></li></ul><ul><li><p><span>MLM —— </span><span style="color:blue; font-family:楷体; font-weight:bold;"><span>带掩码的语言模型（Masked Language Model）</span></span></p><ul><li><p><span>BERT使用Transformer的</span><span style="color:red"><span>双向编码器</span></span><span>表示来改进基于微调的方法；</span></p><ul><li><p><span>Transformer架构通过自注意力机制和学习文本中的长距离依赖关系，使得模型具有出色的全局视野。</span></p></li></ul></li><li><p><span>使用</span><span style="color:blue; font-family:楷体; font-weight:bold;"><span>带掩码的语言模型（Masked Language Model, MLM）</span></span><span>对双向的Transformer进行预训练，缓解了单向性约束，</span><span style="border-bottom: 2px dashed FireBrick;"><span>生成深度的双向语言表征</span></span><span>。</span></p><ul><li><p><span>在BERT的训练过程中，一些单词会被有目的地遮盖住，然后模型需要尝试填充这些被遮盖的单词，从而使模型能够更好地关注上下文信息。</span></p></li><li><p><span>MLM使得能融合左右上下文，所以才能预训练深度双向Transformer，受到了Cloze的启发（1953年的论文，确实让人震惊）</span></p></li></ul></li></ul><p><strong style="color:red"><span>※</span></strong><span> MLM的具体工作</span></p><ul><li><p><span>其实就是每一次随机选择一些字，然后</span><strong><span>“盖住”</span></strong><span>（mask），</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>目标函数</span></span><span>显而易见了，→（根据上下文） </span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>预测那些被盖住的字</span></span><span>。</span></p><p><strong style="color:red"><span>※</span></strong><span> 有点像</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>完形填空</span></span><span>的感觉。对，就是这样！</span></p><ul><li><p><span>有了这个概念，我们就方便理解了，做完形填空的时候，就是不仅要看左边的文段，还要看右边的文段才行。</span></p></li></ul><p><strong style="color:red"><span>※</span></strong><span> MLM除了完形填空之外，对于</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>句子匹配</span></span><span>也是有帮助的。</span></p><ul><li><p><span>句子匹配：随机的选择两个句子，</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>目标函数</span></span><span>是</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>要判断这两个句子在原文中是不是相邻的</span></span><span>。 </span></p></li></ul></li></ul></li></ul><blockquote><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>有标注的数据集一定好吗？</span></kbd></p><p><span>事实上，BERT和它之后的一些工作证明了，有些时候，在NLP任务上，</span><span style="color:red"><span>通过没有标号的、大量的数据集训练的模型</span></span><span>，效果比</span><span style="color:pink"><span>有标注的、规模小一些的数据集上</span></span><span>，效果更好。</span></p></blockquote><p>&nbsp;</p><h3 id='bert预训练和微调'><span>BERT预训练和微调</span></h3><blockquote><p><span>BERT架构两部曲：pre-training &amp; fine-tuning</span></p><ul><li><p><span>pre-training：在不同的任务中，基于无标签数据集进行训练；</span></p></li><li><p><span>fine-tuning：先用</span><span style="color:red"><span>预训练得到的参数</span></span><span>初始化BERT模型，再在特定的</span><span style="color:#2196f3;font-weight:bold"><span>不同的</span></span><span style="color:red"><span>下游任务</span></span><span>上对所有参数微调。</span></p></li></ul><p><span>BERT使用统一的预训练模型架构，能够处理不同的下游任务，不同下游任务的差异较小。</span></p></blockquote><p><span>预训练（Pre-Training）</span></p><ul><li><p><span>预训练主要的工作是：在一个没有标注的数据集上训练BERT模型。</span></p><ul><li><p><span>关键点1：目标函数；</span></p></li><li><p><span>关键点2：预训练数据。</span></p></li></ul></li></ul><p><span>微调（Fine-Tuning）</span></p><ul><li><p><span>同样是用的BERT模型，但是</span><span style="color:red"><span>初始化权重为预训练过程中得到的权重</span></span><span>。</span></p><ul><li><p><span>所有的权重，在微调的过程中都会参与训练，并且用的是有标号的数据。</span></p></li></ul></li></ul><p>&nbsp;</p><p><span>基于预训练得到的模型，在每个后续的下游任务中都会训练出适用于当前任务的模型。</span></p><p><img src=".\pp003_files\image-20240813113710836.png" alt="image-20240813113710836" style="border-radius:10px; border:1px solid #ab0000;"/></p><center><p>预训练和微调的图示（<span style="color:red">以问答为例</span>）</p></center><h2 id='深入bert模型'><span>深入BERT模型</span></h2><p><span>简而言之，就是一个多层的、双向的Transformer编码器（</span><span style="color:#00b456"><span>multi-layer</span></span><span> </span><span style="color:blue"><span>bidirectional</span></span><span> </span><span style="color:red"><span>Transformer encoder</span></span><span>）。</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>BERT在实现上几乎与Transformer encoder完全相同。</span></span></p><p>&nbsp;</p><p><span>BERT调整了Transformer的三个参数：</span></p><ol start='' ><li><p><span style="color:red"><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.541ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 681 683" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-534-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43F" xlink:href="#MJX-534-TEX-I-1D43F"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">L</script></span><span> —— Transformer 块（block）的个数（</span><span style="color:red"><span>the number of layers</span></span><span>）</span></p></li><li><p><span style="color:red"><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-527-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-527-TEX-I-1D43B"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>H</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">H</script></span><span> —— 隐藏层维数（</span><span style="color:red"><span>the hidden size</span></span><span>）</span></p></li><li><p><span style="color:red"><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-396-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D434" xlink:href="#MJX-396-TEX-I-1D434"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">A</script></span><span> —— 自注意力机制的多头的头的数目（head的数目）（</span><span style="color:red"><span>the number of self-attention heads</span></span><span> ）</span></p></li></ol><ul><li><p><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="63.496ex" height="2.059ex" role="img" focusable="false" viewBox="0 -716 28065.4 910" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.439ex;"><defs><path id="MJX-524-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-524-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-524-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-524-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-524-TEX-N-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path id="MJX-524-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path id="MJX-524-TEX-N-3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJX-524-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-524-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-524-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-524-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-524-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-524-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-524-TEX-N-37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path><path id="MJX-524-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-524-TEX-N-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path id="MJX-524-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-524-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-524-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-524-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-524-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-524-TEX-N-50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z"></path><path id="MJX-524-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-524-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-524-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-524-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-524-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-524-TEX-I-1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-524-TEX-N-42"></use><use data-c="45" xlink:href="#MJX-524-TEX-N-45" transform="translate(708,0)"></use><use data-c="52" xlink:href="#MJX-524-TEX-N-52" transform="translate(1389,0)"></use><use data-c="54" xlink:href="#MJX-524-TEX-N-54" transform="translate(2125,0)"></use></g><g data-mml-node="TeXAtom" transform="translate(2880,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-524-TEX-N-42"></use><use data-c="41" xlink:href="#MJX-524-TEX-N-41" transform="translate(708,0)"></use><use data-c="53" xlink:href="#MJX-524-TEX-N-53" transform="translate(1458,0)"></use><use data-c="45" xlink:href="#MJX-524-TEX-N-45" transform="translate(2014,0)"></use></g></g></g></g><g data-mml-node="mo" transform="translate(5113.4,0)"><use data-c="3A" xlink:href="#MJX-524-TEX-N-3A"></use></g><g data-mml-node="mi" transform="translate(5669.2,0)"><use data-c="1D43F" xlink:href="#MJX-524-TEX-I-1D43F"></use></g><g data-mml-node="mo" transform="translate(6628,0)"><use data-c="3D" xlink:href="#MJX-524-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(7683.8,0)"><use data-c="31" xlink:href="#MJX-524-TEX-N-31"></use><use data-c="32" xlink:href="#MJX-524-TEX-N-32" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(8683.8,0)"><use data-c="2C" xlink:href="#MJX-524-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(9128.4,0)"><use data-c="1D43B" xlink:href="#MJX-524-TEX-I-1D43B"></use></g><g data-mml-node="mo" transform="translate(10294.2,0)"><use data-c="3D" xlink:href="#MJX-524-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(11350,0)"><use data-c="37" xlink:href="#MJX-524-TEX-N-37"></use><use data-c="36" xlink:href="#MJX-524-TEX-N-36" transform="translate(500,0)"></use><use data-c="38" xlink:href="#MJX-524-TEX-N-38" transform="translate(1000,0)"></use></g><g data-mml-node="mo" transform="translate(12850,0)"><use data-c="2C" xlink:href="#MJX-524-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(13294.7,0)"><use data-c="1D434" xlink:href="#MJX-524-TEX-I-1D434"></use></g><g data-mml-node="mo" transform="translate(14322.4,0)"><use data-c="3D" xlink:href="#MJX-524-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(15378.2,0)"><use data-c="31" xlink:href="#MJX-524-TEX-N-31"></use><use data-c="32" xlink:href="#MJX-524-TEX-N-32" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(16378.2,0)"><use data-c="2C" xlink:href="#MJX-524-TEX-N-2C"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(16822.9,0)"><g data-mml-node="mi"><use data-c="54" xlink:href="#MJX-524-TEX-N-54"></use><use data-c="6F" xlink:href="#MJX-524-TEX-N-6F" transform="translate(722,0)"></use><use data-c="74" xlink:href="#MJX-524-TEX-N-74" transform="translate(1222,0)"></use><use data-c="61" xlink:href="#MJX-524-TEX-N-61" transform="translate(1611,0)"></use><use data-c="6C" xlink:href="#MJX-524-TEX-N-6C" transform="translate(2111,0)"></use></g><g data-mml-node="mi" transform="translate(2389,0)"><use data-c="50" xlink:href="#MJX-524-TEX-N-50"></use><use data-c="61" xlink:href="#MJX-524-TEX-N-61" transform="translate(681,0)"></use><use data-c="72" xlink:href="#MJX-524-TEX-N-72" transform="translate(1181,0)"></use><use data-c="61" xlink:href="#MJX-524-TEX-N-61" transform="translate(1573,0)"></use><use data-c="6D" xlink:href="#MJX-524-TEX-N-6D" transform="translate(2073,0)"></use><use data-c="65" xlink:href="#MJX-524-TEX-N-65" transform="translate(2906,0)"></use><use data-c="74" xlink:href="#MJX-524-TEX-N-74" transform="translate(3350,0)"></use><use data-c="65" xlink:href="#MJX-524-TEX-N-65" transform="translate(3739,0)"></use><use data-c="72" xlink:href="#MJX-524-TEX-N-72" transform="translate(4183,0)"></use><use data-c="73" xlink:href="#MJX-524-TEX-N-73" transform="translate(4575,0)"></use></g></g><g data-mml-node="mo" transform="translate(24458.7,0)"><use data-c="3D" xlink:href="#MJX-524-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(25514.4,0)"><use data-c="31" xlink:href="#MJX-524-TEX-N-31"></use><use data-c="31" xlink:href="#MJX-524-TEX-N-31" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-524-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mi" transform="translate(27014.4,0)"><use data-c="1D440" xlink:href="#MJX-524-TEX-I-1D440"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi data-mjx-auto-op="false">BERT</mi><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">BASE</mi></mrow></msub></mrow><mo>:</mo><mi>L</mi><mo>=</mo><mn>12</mn><mo>,</mo><mi>H</mi><mo>=</mo><mn>768</mn><mo>,</mo><mi>A</mi><mo>=</mo><mn>12</mn><mo>,</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">Total</mi><mi data-mjx-auto-op="false">Parameters</mi></mrow><mo>=</mo><mn>110</mn><mi>M</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{BERT_{BASE}}: L=12, H=768, A=12, \mathrm{Total Parameters}=110M</script></p><p><span style="border-bottom: 2px dashed FireBrick;"><span> （the same model size as OpenAI GPT）</span></span></p></li><li><p><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="66.039ex" height="2.059ex" role="img" focusable="false" viewBox="0 -716 29189.1 910" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.439ex;"><defs><path id="MJX-525-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-525-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-525-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-525-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-525-TEX-N-4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path><path id="MJX-525-TEX-N-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path id="MJX-525-TEX-N-47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path><path id="MJX-525-TEX-N-3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJX-525-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-525-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-525-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-525-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-525-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-525-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-525-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-525-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-525-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-525-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-525-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-525-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-525-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-525-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-525-TEX-N-50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z"></path><path id="MJX-525-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-525-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-525-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-525-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-525-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-525-TEX-I-1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-525-TEX-N-42"></use><use data-c="45" xlink:href="#MJX-525-TEX-N-45" transform="translate(708,0)"></use><use data-c="52" xlink:href="#MJX-525-TEX-N-52" transform="translate(1389,0)"></use><use data-c="54" xlink:href="#MJX-525-TEX-N-54" transform="translate(2125,0)"></use></g><g data-mml-node="TeXAtom" transform="translate(2880,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4C" xlink:href="#MJX-525-TEX-N-4C"></use><use data-c="41" xlink:href="#MJX-525-TEX-N-41" transform="translate(625,0)"></use><use data-c="52" xlink:href="#MJX-525-TEX-N-52" transform="translate(1375,0)"></use><use data-c="47" xlink:href="#MJX-525-TEX-N-47" transform="translate(2111,0)"></use><use data-c="45" xlink:href="#MJX-525-TEX-N-45" transform="translate(2896,0)"></use></g></g></g></g><g data-mml-node="mo" transform="translate(5737.1,0)"><use data-c="3A" xlink:href="#MJX-525-TEX-N-3A"></use></g><g data-mml-node="mi" transform="translate(6292.9,0)"><use data-c="1D43F" xlink:href="#MJX-525-TEX-I-1D43F"></use></g><g data-mml-node="mo" transform="translate(7251.7,0)"><use data-c="3D" xlink:href="#MJX-525-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(8307.4,0)"><use data-c="32" xlink:href="#MJX-525-TEX-N-32"></use><use data-c="34" xlink:href="#MJX-525-TEX-N-34" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(9307.4,0)"><use data-c="2C" xlink:href="#MJX-525-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(9752.1,0)"><use data-c="1D43B" xlink:href="#MJX-525-TEX-I-1D43B"></use></g><g data-mml-node="mo" transform="translate(10917.9,0)"><use data-c="3D" xlink:href="#MJX-525-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(11973.7,0)"><use data-c="31" xlink:href="#MJX-525-TEX-N-31"></use><use data-c="30" xlink:href="#MJX-525-TEX-N-30" transform="translate(500,0)"></use><use data-c="32" xlink:href="#MJX-525-TEX-N-32" transform="translate(1000,0)"></use><use data-c="34" xlink:href="#MJX-525-TEX-N-34" transform="translate(1500,0)"></use></g><g data-mml-node="mo" transform="translate(13973.7,0)"><use data-c="2C" xlink:href="#MJX-525-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(14418.3,0)"><use data-c="1D434" xlink:href="#MJX-525-TEX-I-1D434"></use></g><g data-mml-node="mo" transform="translate(15446.1,0)"><use data-c="3D" xlink:href="#MJX-525-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(16501.9,0)"><use data-c="31" xlink:href="#MJX-525-TEX-N-31"></use><use data-c="36" xlink:href="#MJX-525-TEX-N-36" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(17501.9,0)"><use data-c="2C" xlink:href="#MJX-525-TEX-N-2C"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(17946.5,0)"><g data-mml-node="mi"><use data-c="54" xlink:href="#MJX-525-TEX-N-54"></use><use data-c="6F" xlink:href="#MJX-525-TEX-N-6F" transform="translate(722,0)"></use><use data-c="74" xlink:href="#MJX-525-TEX-N-74" transform="translate(1222,0)"></use><use data-c="61" xlink:href="#MJX-525-TEX-N-61" transform="translate(1611,0)"></use><use data-c="6C" xlink:href="#MJX-525-TEX-N-6C" transform="translate(2111,0)"></use></g><g data-mml-node="mi" transform="translate(2389,0)"><use data-c="50" xlink:href="#MJX-525-TEX-N-50"></use><use data-c="61" xlink:href="#MJX-525-TEX-N-61" transform="translate(681,0)"></use><use data-c="72" xlink:href="#MJX-525-TEX-N-72" transform="translate(1181,0)"></use><use data-c="61" xlink:href="#MJX-525-TEX-N-61" transform="translate(1573,0)"></use><use data-c="6D" xlink:href="#MJX-525-TEX-N-6D" transform="translate(2073,0)"></use><use data-c="65" xlink:href="#MJX-525-TEX-N-65" transform="translate(2906,0)"></use><use data-c="74" xlink:href="#MJX-525-TEX-N-74" transform="translate(3350,0)"></use><use data-c="65" xlink:href="#MJX-525-TEX-N-65" transform="translate(3739,0)"></use><use data-c="72" xlink:href="#MJX-525-TEX-N-72" transform="translate(4183,0)"></use><use data-c="73" xlink:href="#MJX-525-TEX-N-73" transform="translate(4575,0)"></use></g></g><g data-mml-node="mo" transform="translate(25582.3,0)"><use data-c="3D" xlink:href="#MJX-525-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(26638.1,0)"><use data-c="33" xlink:href="#MJX-525-TEX-N-33"></use><use data-c="34" xlink:href="#MJX-525-TEX-N-34" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-525-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mi" transform="translate(28138.1,0)"><use data-c="1D440" xlink:href="#MJX-525-TEX-I-1D440"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi data-mjx-auto-op="false">BERT</mi><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">LARGE</mi></mrow></msub></mrow><mo>:</mo><mi>L</mi><mo>=</mo><mn>24</mn><mo>,</mo><mi>H</mi><mo>=</mo><mn>1024</mn><mo>,</mo><mi>A</mi><mo>=</mo><mn>16</mn><mo>,</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">Total</mi><mi data-mjx-auto-op="false">Parameters</mi></mrow><mo>=</mo><mn>340</mn><mi>M</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{BERT_{LARGE}}: L=24, H=1024, A=16, \mathrm{Total Parameters}=340M</script></p></li></ul><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>表格</span></kbd><span> </span><strong><span>BERT是以Transformer为基础的，目前有</span><u><span>两种</span></u><span>变体。</span></strong><span> </span></p><figure class='table-figure'><table><thead><tr><th><span>Model</span></th><th><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.541ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 681 683" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-534-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43F" xlink:href="#MJX-534-TEX-I-1D43F"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">L</script></th><th><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-527-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-527-TEX-I-1D43B"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>H</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">H</script><span>（Hidden）</span></th><th><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-396-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D434" xlink:href="#MJX-396-TEX-I-1D434"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">A</script></th><th><span>参数个数</span></th></tr></thead><tbody><tr><td><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="10.94ex" height="1.926ex" role="img" focusable="false" viewBox="0 -683 4835.7 851.2" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.381ex;"><defs><path id="MJX-536-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-536-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-536-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-536-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-536-TEX-N-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path id="MJX-536-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-536-TEX-N-42"></use><use data-c="45" xlink:href="#MJX-536-TEX-N-45" transform="translate(708,0)"></use><use data-c="52" xlink:href="#MJX-536-TEX-N-52" transform="translate(1389,0)"></use><use data-c="54" xlink:href="#MJX-536-TEX-N-54" transform="translate(2125,0)"></use></g><g data-mml-node="TeXAtom" transform="translate(2880,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-536-TEX-N-42"></use><use data-c="41" xlink:href="#MJX-536-TEX-N-41" transform="translate(708,0)"></use><use data-c="53" xlink:href="#MJX-536-TEX-N-53" transform="translate(1458,0)"></use><use data-c="45" xlink:href="#MJX-536-TEX-N-45" transform="translate(2014,0)"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi data-mjx-auto-op="false">BERT</mi><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">BASE</mi></mrow></msub></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{BERT_{BASE}}</script></td><td><span style="color:red"><span>12</span></span><span>层（Transformer blocks）</span></td><td><span>768</span></td><td><span style="color:red"><span>12</span></span><span>个（Attention head）</span></td><td><span>1.1亿</span></td></tr><tr><td><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="12.351ex" height="1.926ex" role="img" focusable="false" viewBox="0 -683 5459.3 851.2" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.381ex;"><defs><path id="MJX-529-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-529-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-529-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-529-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-529-TEX-N-4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path><path id="MJX-529-TEX-N-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path id="MJX-529-TEX-N-47" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q401 658 376 654T316 633T254 592T205 519T177 411Q173 369 173 335Q173 259 192 201T238 111T302 58T370 31T431 24Q478 24 513 45T559 100Q562 110 562 160V212Q561 213 557 216T551 220T542 223T526 225T502 226T463 227H437V273H449L609 270Q715 270 727 273H735V227H721Q674 227 668 215Q666 211 666 108V6Q660 0 657 0Q653 0 639 10Q617 25 600 42L587 54Q571 27 524 3T406 -22Q317 -22 238 22T108 151T56 342Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-529-TEX-N-42"></use><use data-c="45" xlink:href="#MJX-529-TEX-N-45" transform="translate(708,0)"></use><use data-c="52" xlink:href="#MJX-529-TEX-N-52" transform="translate(1389,0)"></use><use data-c="54" xlink:href="#MJX-529-TEX-N-54" transform="translate(2125,0)"></use></g><g data-mml-node="TeXAtom" transform="translate(2880,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4C" xlink:href="#MJX-529-TEX-N-4C"></use><use data-c="41" xlink:href="#MJX-529-TEX-N-41" transform="translate(625,0)"></use><use data-c="52" xlink:href="#MJX-529-TEX-N-52" transform="translate(1375,0)"></use><use data-c="47" xlink:href="#MJX-529-TEX-N-47" transform="translate(2111,0)"></use><use data-c="45" xlink:href="#MJX-529-TEX-N-45" transform="translate(2896,0)"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi data-mjx-auto-op="false">BERT</mi><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">LARGE</mi></mrow></msub></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{BERT_{LARGE}}</script></td><td><span style="color:red"><span>24</span></span><span>层（Transformer blocks）</span></td><td><span>1024</span></td><td><span style="color:red"><span>16</span></span><span>个（Attention head）</span></td><td><span>3.4亿</span></td></tr></tbody></table></figure><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>图示</span></kbd><span> 图片来源：</span><a href='http://jalammar.github.io/illustrated-bert/' target='_blank' class='url'>http://jalammar.github.io/illustrated-bert/</a><span>（</span><span style="color:blue; font-family:楷体; font-weight:bold;"><span>值得好好再看看</span></span><span>）</span></p><p><img src=".\pp003_files\image-20240815160237250.png" referrerpolicy="no-referrer" alt="image-20240815160237250"></p><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>问题</span></kbd><span> 如何把超参数换算成可学习参数的大小呢？</span></p><h3 id='bert模型可学习参数计算'><span>BERT模型可学习参数计算</span></h3><p><span>可学习参数主要分为两块：</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>嵌入层</span></span><span>、</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>Transformer块</span></span><span>。过程图如下。</span></p><p><img src=".\pp003_files\image-20240813162437038.png" referrerpolicy="no-referrer" alt="image-20240813162437038"></p><p><span>自注意力机制本身并没有可学习参数，但是对于多头注意力，会把进入的所有K(key)、V(value)、Q(Query)都做一次投影，每次投影的维度为64，而且有</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="11.751ex" height="1.805ex" role="img" focusable="false" viewBox="0 -716 5194 798" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.186ex;"><defs><path id="MJX-530-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-530-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-530-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-530-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-530-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-530-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D434" xlink:href="#MJX-530-TEX-I-1D434"></use></g><g data-mml-node="mo" transform="translate(972.2,0)"><use data-c="D7" xlink:href="#MJX-530-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(1972.4,0)"><use data-c="36" xlink:href="#MJX-530-TEX-N-36"></use><use data-c="34" xlink:href="#MJX-530-TEX-N-34" transform="translate(500,0)"></use></g><g data-mml-node="mo" transform="translate(3250.2,0)"><use data-c="3D" xlink:href="#MJX-530-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(4306,0)"><use data-c="1D43B" xlink:href="#MJX-530-TEX-I-1D43B"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><mo>×</mo><mn>64</mn><mo>=</mo><mi>H</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">A \times 64 = H</script><span>；</span></p><p><span>如上，前面的自注意力块有</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="4.248ex" height="1.887ex" role="img" focusable="false" viewBox="0 -833.9 1877.4 833.9" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-531-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-531-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-531-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><use data-c="34" xlink:href="#MJX-531-TEX-N-34"></use></g><g data-mml-node="msup" transform="translate(500,0)"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-531-TEX-I-1D43B"></use></g><g data-mml-node="mn" transform="translate(973.9,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-531-TEX-N-32"></use></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><msup><mi>H</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container><script type="math/tex">4H^2</script><span>个参数，MLP有 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="19.077ex" height="2.072ex" role="img" focusable="false" viewBox="0 -833.9 8431.8 915.9" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.186ex;"><defs><path id="MJX-532-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-532-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-532-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-532-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-532-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-532-TEX-N-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-532-TEX-I-1D43B"></use></g><g data-mml-node="mo" transform="translate(1110.2,0)"><use data-c="D7" xlink:href="#MJX-532-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(2110.4,0)"><use data-c="34" xlink:href="#MJX-532-TEX-N-34"></use></g><g data-mml-node="mi" transform="translate(2610.4,0)"><use data-c="1D43B" xlink:href="#MJX-532-TEX-I-1D43B"></use></g><g data-mml-node="mo" transform="translate(3720.7,0)"><use data-c="D7" xlink:href="#MJX-532-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(4720.9,0)"><use data-c="32" xlink:href="#MJX-532-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(5498.7,0)"><use data-c="3D" xlink:href="#MJX-532-TEX-N-3D"></use></g><g data-mml-node="mstyle" fill="red" stroke="red" transform="translate(6554.4,0)"><g data-mml-node="mn"><use data-c="38" xlink:href="#MJX-532-TEX-N-38"></use></g><g data-mml-node="msup" transform="translate(500,0)"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-532-TEX-I-1D43B"></use></g><g data-mml-node="mn" transform="translate(973.9,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-532-TEX-N-32"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>H</mi><mo>×</mo><mn>4</mn><mi>H</mi><mo>×</mo><mn>2</mn><mo>=</mo><mstyle mathcolor="red"><mn>8</mn><msup><mi>H</mi><mn>2</mn></msup></mstyle></math></mjx-assistive-mml></mjx-container><script type="math/tex">H\times4H\times2=\textcolor{red}{8H^2}</script><span> 个参数，则每个Transformer块中有</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="5.379ex" height="1.887ex" role="img" focusable="false" viewBox="0 -833.9 2377.4 833.9" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-533-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-533-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-533-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="mn"><use data-c="31" xlink:href="#MJX-533-TEX-N-31"></use><use data-c="32" xlink:href="#MJX-533-TEX-N-32" transform="translate(500,0)"></use></g><g data-mml-node="msup" transform="translate(1000,0)"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-533-TEX-I-1D43B"></use></g><g data-mml-node="mn" transform="translate(973.9,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-533-TEX-N-32"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle mathcolor="red"><mn>12</mn><msup><mi>H</mi><mn>2</mn></msup></mstyle></math></mjx-assistive-mml></mjx-container><script type="math/tex">\textcolor{red}{12H^2}</script><span>个参数；</span></p><p><span>最后再乘</span><span style="color:red"><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.541ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 681 683" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-534-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43F" xlink:href="#MJX-534-TEX-I-1D43F"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">L</script></span><span>和</span><span style="color:red"><span>字典大小</span></span><span>，得到</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="25.107ex" height="2.072ex" role="img" focusable="false" viewBox="0 -833.9 11097.4 915.9" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.186ex;"><defs><path id="MJX-535-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-535-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-535-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-535-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-535-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-535-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-535-TEX-I-1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-535-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-535-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-535-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-535-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D446" xlink:href="#MJX-535-TEX-I-1D446"></use></g><g data-mml-node="mi" transform="translate(645,0)"><use data-c="1D462" xlink:href="#MJX-535-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1217,0)"><use data-c="1D45A" xlink:href="#MJX-535-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(2372.8,0)"><use data-c="3D" xlink:href="#MJX-535-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(3428.6,0)"><use data-c="33" xlink:href="#MJX-535-TEX-N-33"></use><use data-c="30" xlink:href="#MJX-535-TEX-N-30" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-535-TEX-N-30" transform="translate(1000,0)"></use><use data-c="30" xlink:href="#MJX-535-TEX-N-30" transform="translate(1500,0)"></use><use data-c="30" xlink:href="#MJX-535-TEX-N-30" transform="translate(2000,0)"></use></g><g data-mml-node="mi" transform="translate(5928.6,0)"><use data-c="1D43B" xlink:href="#MJX-535-TEX-I-1D43B"></use></g><g data-mml-node="mo" transform="translate(7038.8,0)"><use data-c="2B" xlink:href="#MJX-535-TEX-N-2B"></use></g><g data-mml-node="mn" transform="translate(8039,0)"><use data-c="31" xlink:href="#MJX-535-TEX-N-31"></use><use data-c="32" xlink:href="#MJX-535-TEX-N-32" transform="translate(500,0)"></use></g><g data-mml-node="mi" transform="translate(9039,0)"><use data-c="1D43F" xlink:href="#MJX-535-TEX-I-1D43F"></use></g><g data-mml-node="msup" transform="translate(9720,0)"><g data-mml-node="mi"><use data-c="1D43B" xlink:href="#MJX-535-TEX-I-1D43B"></use></g><g data-mml-node="mn" transform="translate(973.9,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-535-TEX-N-32"></use></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi><mi>u</mi><mi>m</mi><mo>=</mo><mn>30000</mn><mi>H</mi><mo>+</mo><mn>12</mn><mi>L</mi><msup><mi>H</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container><script type="math/tex">Sum=30000H+12LH^2</script><span>，代入</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="10.94ex" height="1.926ex" role="img" focusable="false" viewBox="0 -683 4835.7 851.2" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.381ex;"><defs><path id="MJX-536-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-536-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-536-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-536-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-536-TEX-N-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path><path id="MJX-536-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-536-TEX-N-42"></use><use data-c="45" xlink:href="#MJX-536-TEX-N-45" transform="translate(708,0)"></use><use data-c="52" xlink:href="#MJX-536-TEX-N-52" transform="translate(1389,0)"></use><use data-c="54" xlink:href="#MJX-536-TEX-N-54" transform="translate(2125,0)"></use></g><g data-mml-node="TeXAtom" transform="translate(2880,-152.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-536-TEX-N-42"></use><use data-c="41" xlink:href="#MJX-536-TEX-N-41" transform="translate(708,0)"></use><use data-c="53" xlink:href="#MJX-536-TEX-N-53" transform="translate(1458,0)"></use><use data-c="45" xlink:href="#MJX-536-TEX-N-45" transform="translate(2014,0)"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi data-mjx-auto-op="false">BERT</mi><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">BASE</mi></mrow></msub></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{BERT_{BASE}}</script><span>可以获得确实是110M个参数。</span></p><h3 id='bert-输入--输出'><span>BERT </span><code>输入</code><span> &amp; </span><code>输出</code></h3><p><kbd style="background:yellow; color:red"><span>目标</span></kbd><span> 为了使BERT能处理大量不同的下游任务，作者将模型的</span><span style="border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red; font-weight:bold"><span>输入</span></span><span>设计成</span><span style="text-decoration: underline #990000; text-decoration-style: wavy;"><span>可以输入单个句子或句子对</span></span><span>，这两种输入被建模成</span><span style="color:red"><span>同一个token序列</span></span><span>。</span><span style="border-bottom: 2px dashed FireBrick;"><span>作者使用了有30000个 token 的vocabulary 词嵌入</span></span><span>。</span></p><p><span style="border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red; font-weight:bold"><span>输入</span></span><span> 既可以是“</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>句子</span></span><span>”，也可以是“</span><span style="border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red;"><span>句子对</span></span><span>”。不过事实上，这里的句子和句子对都不是狭义的概念，事实上是一个“</span><strong><span>序列</span></strong><span>”。</span></p><p><kbd style="border:1px dotted #990000; font-size:15px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>输入序列</span></kbd><span> 第一个token都是一个特殊标记</span><code>[CLS]</code><span>，该标记的</span><span style="color:red"><span>最终隐藏状态</span></span><span>用来聚合句子的表征，从而实现</span><span style="border-bottom: 2px dashed FireBrick;"><span>分类任务</span></span><span>。对于sentence对，作者使用特殊标记</span><code>[SEP]</code><span>来区分不同的句子。</span></p><p><kbd style="border:1px dotted #990000; font-size:15px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>输出序列</span></kbd><span> 用 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.541ex" height="1.538ex" role="img" focusable="false" viewBox="0 -680 681 680" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-537-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="mi"><use data-c="45" xlink:href="#MJX-537-TEX-N-45"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mstyle mathcolor="red"><mi mathvariant="normal">E</mi></mstyle></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{\textcolor{red}{E}}</script><span> 来表示输入的embedding，</span><code>[CLS]</code><span>的最终隐藏状态为</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="7.421ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 3279.9 886" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.09ex;"><defs><path id="MJX-542-TEX-N-43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path><path id="MJX-542-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-542-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-542-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="43" xlink:href="#MJX-542-TEX-N-43"></use></g><g data-mml-node="mo" transform="translate(999.8,0)"><use data-c="2208" xlink:href="#MJX-542-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(1944.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-542-TEX-D-211D"></use></g></g><g data-mml-node="mi" transform="translate(755,363) scale(0.707)"><use data-c="48" xlink:href="#MJX-542-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mi mathvariant="normal">H</mi></msup></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{C \in \mathbb{R}^H}</script><span> ，输入序列的第 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="0.629ex" height="1.514ex" role="img" focusable="false" viewBox="0 -669 278 669" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-539-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="mi"><use data-c="69" xlink:href="#MJX-539-TEX-N-69"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mstyle mathcolor="red"><mi mathvariant="normal">i</mi></mstyle></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{\textcolor{red}{i}}</script><span> 个token的隐藏向量为</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="8.053ex" height="2.253ex" role="img" focusable="false" viewBox="0 -846 3559.5 996" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.339ex;"><defs><path id="MJX-543-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-543-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-543-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-543-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-543-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="54" xlink:href="#MJX-543-TEX-N-54"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="69" xlink:href="#MJX-543-TEX-N-69"></use></g></g><g data-mml-node="mo" transform="translate(1279.4,0)"><use data-c="2208" xlink:href="#MJX-543-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(2224.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-543-TEX-D-211D"></use></g></g><g data-mml-node="mi" transform="translate(755,363) scale(0.707)"><use data-c="48" xlink:href="#MJX-543-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi mathvariant="normal">T</mi><mi mathvariant="normal">i</mi></msub><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mi mathvariant="normal">H</mi></msup></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{T_i\in\mathbb{R}^H}</script><span> 。对于</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.266ex" height="1.871ex" role="img" focusable="false" viewBox="0 -677 1001.6 827" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.339ex;"><defs><path id="MJX-541-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-541-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="54" xlink:href="#MJX-541-TEX-N-54"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="69" xlink:href="#MJX-541-TEX-N-69"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi mathvariant="normal">T</mi><mi mathvariant="normal">i</mi></msub></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{T_i}</script><span>，都是通过token embedding、segment embedding、position embedding加和构造出来的。如下图所示：</span></p><p><img src=".\pp003_files\image-20240813165317572.png" alt="image-20240813165317572" style="border-radius:10px; border:1px solid #ab0000;"/></p><p><span>因为BERT不同于一般的Transformer，</span><span style="color:blue; font-family:Times New Roman, 仿宋; font-weight:bold"><span>BERT只有编码器</span></span><span>，而Transformer有编码器和解码器，</span><span style="border-bottom: 2px dashed FireBrick;"><span>所以为了能够处理两个句子的情况，需要</span><span style="color:red"><span>把两个句子变成一个序列</span></span></span><span>。</span></p><p><strong style="color:red"><span>※</span></strong><span> BERT模型将不同的输入统一为单一输入序列，以处理多样化输入的</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>下游任务</span></span><span>，如</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>单句输入的NER任务</span></span><span>、</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>多句输入的QA任务</span></span><span>等。</span></p><p><strong style="color:red"><span>※</span></strong><span> 输入序列的处理方式</span></p><ul><li><p><span>使用</span><code>[CLS]</code><span>作为每个输入序列的第一个token，其最终一个隐藏状态的输出可用于下游分类任务</span></p><ul><li><p><code>[CLS]</code><span>是每个输入示例开头的特殊标记</span></p></li></ul></li><li><p><span>使用</span><code>[SEP]</code><span>连接不同句子的输入序列</span></p><ul><li><p><code>[SEP]</code><span>是一个特殊的标记用于区分Question / Answer（</span><span style="color:blue"><span>在问答案例中</span></span><span>）</span></p></li></ul></li><li><p><span>每个token加上位置嵌入（mask），区别token属于哪个句子。</span></p></li></ul><h4 id='切词方法wordpiece'><span>切词方法：</span><span style="color:blue; font-family:Comic Sans MS"><span>WordPiece</span></span></h4><p><span style="color:#2196f3;font-weight:bold"><span>切词方法1</span></span><span>：如果说</span><span style="color:red"><span>按照空格</span></span><span>来切词的话，也就是</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>一个词</span></span><span>对应</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>一个Token</span></span><span>，那样会导致字典大小特别大，根据上文的可学习参数计算方法，这会导致参数太多而且集中在</span><span style="border-bottom: 2px dotted FireBrick;"><span>嵌入层</span></span><span>上面。</span></p><p><span style="color:#2196f3;font-weight:bold"><span>切词方法2</span></span><span>：而</span><span style="color:blue; font-family:Comic Sans MS"><span>WordPiece</span></span><span>的想法（</span><span style="color:red"><span>概率 + 词根</span></span><span>）</span></p><ul><li><p><span>如果一个词在整个文段里出现的</span><span style="color:blue"><span>概率不大</span></span><span>的话，应该切开，看其子序列（有可能是一个词根）。</span></p></li><li><p><span>如果一个词根出现的</span><span style="color:blue"><span>概率比较大</span></span><span>的话，就</span><span style="border-bottom: 2px dashed FireBrick;"><span>只保留词根</span></span><span>就好了，这样的话会让字典大小缩小不少。</span></p></li></ul><h4 id='合并句子的方法'><span>合并句子的方法：</span></h4><p><span>每一个序列的第一个词都是</span><code>[cls]</code><span>，代表</span><span style="color:red"><span>classification</span></span><span>，因为最后的</span><span style="border-top: 2px solid black; border-bottom: 2px solid black; border-left: 2px solid black; border-right: 2px solid black; color:red; font-weight:bold"><span>输出</span></span><span>要代表整个序列的一个信息，这是因为BERT使用了Transformer的编码器，所以</span><span style="color:blue"><span>自注意力层</span></span><span>里的</span><span style="border-bottom: 2px dotted FireBrick;"><span>每一个词</span></span><span>都会看输入的所有词的关系，所以可以放在第一个位置。</span></p><p><span>需要对句子进行一定的区分，以</span><span style="color:red"><span>从句子层面进行分类</span></span><span>，这里有两个办法：</span></p><ul><li><p><span>为每个句子的末尾添加一个</span><code>[SEP]</code><span>表示separate；</span></p></li><li><p><span>学习一个嵌入层，来知道某个句子是第一个还是第二个。</span></p></li></ul><p><span>这个时候我们再回去看一下上面给出过的图，就很好理解了：</span></p><p><img src=".\pp003_files\image-20240813113710836.png" alt="image-20240813113710836" style="border-radius:10px; border:1px solid #ab0000;"/></p><center><span style="color:red; font-weight:bold">图1. </span><span style="color:red">以<span style="color:blue">问答为例</span>的预训练 <span style="color:blue">&</span> 微调</span></center><p><span>如上图，每一个Token进入BERT，得到这个Token的Embedding表示。</span></p><ul><li><p><span>如上图（左），输入序列是一对句子A和B，图中各符号的意义：</span></p><ul><li><p><span>句子A和B添加位置嵌入，使用</span><code>[SEP]</code><span>连接为</span><span style="border-bottom: 2px dashed FireBrick;"><span>输入嵌入序列（</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: #ffc9c4"><span>  E  </span></span><span>）</span></span><span> </span></p></li><li><p><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="7.421ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 3279.9 886" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.09ex;"><defs><path id="MJX-542-TEX-N-43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path><path id="MJX-542-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-542-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-542-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="43" xlink:href="#MJX-542-TEX-N-43"></use></g><g data-mml-node="mo" transform="translate(999.8,0)"><use data-c="2208" xlink:href="#MJX-542-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(1944.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-542-TEX-D-211D"></use></g></g><g data-mml-node="mi" transform="translate(755,363) scale(0.707)"><use data-c="48" xlink:href="#MJX-542-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">C</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mi mathvariant="normal">H</mi></msup></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{C \in \mathbb{R}^H}</script><span> 是特殊标记</span><code>[CLS]</code><span>的最后一个隐状态</span></p></li><li><p><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="8.053ex" height="2.253ex" role="img" focusable="false" viewBox="0 -846 3559.5 996" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.339ex;"><defs><path id="MJX-543-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-543-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-543-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-543-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-543-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="54" xlink:href="#MJX-543-TEX-N-54"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="69" xlink:href="#MJX-543-TEX-N-69"></use></g></g><g data-mml-node="mo" transform="translate(1279.4,0)"><use data-c="2208" xlink:href="#MJX-543-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(2224.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-543-TEX-D-211D"></use></g></g><g data-mml-node="mi" transform="translate(755,363) scale(0.707)"><use data-c="48" xlink:href="#MJX-543-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi mathvariant="normal">T</mi><mi mathvariant="normal">i</mi></msub><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mi mathvariant="normal">H</mi></msup></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{T_i\in\mathbb{R}^H}</script><span>是输入序列第 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewBox="0 -661 345 672" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-497-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-497-TEX-I-1D456"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">i</script><span> 位置的最后一个隐状态</span></p></li></ul></li></ul><p>&nbsp;</p><p><span>整体上的效果就是：</span><span style="color:blue; font-family:楷体; font-weight:bold;"><span>输入一个序列，得到一个序列，最后再添加额外的输出层来得到想要的结果</span></span><span>。</span></p><p><strong style="color:red"><span>※</span></strong><span> BERT考虑不同嵌入信息，并对</span><span style="color:#b000e0;font-weight:bold"><span>不同嵌入求和</span></span><span>得到</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: #ffc9c4"><span>输入序列嵌入</span></span><span>。</span></p><p><span>对于每一个词元，进入BERT时的向量表示的是：</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>❶这个词元本身的Embedding + ❷它在哪个位置的Embedding + ❸位置的Embedding</span></span><span>，如下图所示：</span></p><p><img src=".\pp003_files\image-20240813165317572.png" alt="image-20240813165317572" style="border-radius:10px; border:1px solid #ab0000;"/></p><ul><li><p><span style="color:#2196f3;font-weight:bold"><span>Token Embedding</span></span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span> ❶ </span></span><span>： 词元的Embedding层，对于每一个词元，输出一个对应的向量；</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>标记嵌入</span></span><span>：从</span><span style="color:blue; font-family:Comic Sans MS"><span>WordPiece</span></span><span>标记词汇表中学习</span><span style="color:red"><span>特定标记的嵌入</span></span><span>。</span></p></li><li><p><span style="color:#2196f3;font-weight:bold"><span>Segment Embedding</span></span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span> ❷ </span></span><span>：A表示第一句话，B表示第二句话；</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>片段嵌入</span></span><span>：BERT还可以将</span><span style="color:red"><span>句子对</span></span><span>作为任务（问答）的输入。这就是为什么它学习了第一个和第二个句子的嵌入，以帮助模型区分二者。在上面的例子中，所有标记为 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.928ex" height="1.884ex" role="img" focusable="false" viewBox="0 -680 1294.3 832.7" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.345ex;"><defs><path id="MJX-544-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-544-TEX-N-41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mstyle" fill="#990000" stroke="#990000"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="45" xlink:href="#MJX-544-TEX-N-45"></use></g><g data-mml-node="mi" transform="translate(714,-152.7) scale(0.707)"><use data-c="41" xlink:href="#MJX-544-TEX-N-41"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mstyle mathcolor="#990000"><msub><mi mathvariant="normal">E</mi><mi mathvariant="normal">A</mi></msub></mstyle></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{\textcolor{#990000}{E_A}}</script><span> 的标记都属于句A（ </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.861ex" height="1.878ex" role="img" focusable="false" viewBox="0 -680 1264.6 830" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.339ex;"><defs><path id="MJX-545-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-545-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mstyle" fill="#990000" stroke="#990000"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="45" xlink:href="#MJX-545-TEX-N-45"></use></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><use data-c="42" xlink:href="#MJX-545-TEX-N-42"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mstyle mathcolor="#990000"><msub><mi mathvariant="normal">E</mi><mi mathvariant="normal">B</mi></msub></mstyle></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{\textcolor{#990000}{E_B}}</script><span> 同理）。</span></p></li><li><p><span style="color:#2196f3;font-weight:bold"><span>Position Embedding</span></span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span> ❸ </span></span><span>：位置的嵌入层。输入的大小是序列最长有多长，输入的是每一个词元的位置信息（0base）</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>位置嵌入</span></span><span>：BERT学习并使用位置嵌入来表达词在句子中的位置，这些</span><span style="color:red"><span>为了克服Transformer的限制</span></span><span>而添加的。与RNN不同，Transformer不能捕捉“序列”或“顺序”信息。</span></p></li></ul><p><span>对于特定的标记，其输入的表示是</span><span style="color:red"><span>对应的标记</span></span><span>、</span><span style="color:red"><span>片段</span></span><span>和</span><span style="color:red"><span>位置嵌入</span></span><span>之和。这样一个</span><strong style="color:red"><span>综合的嵌入方案</span></strong><span>包含了很多对模型有用的信息。</span></p><p><span>由上图所示，输入序列嵌入是对不同嵌入方式的求和。</span></p><p><span>这些都是通过学习的来的，而不同于Transformer的手动构造。</span></p><p><strong style="color:red"><span>※</span></strong><span> 这些预处理步骤综合起来，</span><span style="border-bottom: 2px dashed FireBrick;"><span>使BERT具有很强的通用性</span></span><span>。</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>这意味着</span></span><span>，如果不对模型的结构进行任何重大更改，就可以轻松地将其训练到多种自然语言处理任务上。 </span></p><h3 id='mlm预训练的细节'><span>MLM预训练的细节</span></h3><blockquote><p><span style="color:red"><span>前文</span></span><span>：使用</span><span style="color:blue; font-family:楷体; font-weight:bold;"><span>带掩码的语言模型（Masked Language Model, MLM）</span></span><span>对双向的Transformer进行预训练，缓解了单向性约束，</span><span style="border-bottom: 2px dashed FireBrick;"><span>生成深度的双向语言表征</span></span><span>。</span></p></blockquote><p><span>知道了切词的方法，我们再来看看所谓的“英语题”。</span></p><p><span>预训练BERT模型（Pre-training BERT）模型使用两种无监督任务：</span><span style="color:blue; font-family:Whitney"><span>Masked LM</span></span><span> 和 </span><span style="color:blue; font-family:Whitney"><span>Next Sentence Prediction(NSP)</span></span><span>。</span></p><p>&nbsp;</p><h4 id='任务1完形填空masked-lm-mlm）'><span>任务1：完形填空（Masked LM, MLM）</span></h4><p><span>标准条件语言模型只能按照</span><span style="color:red"><span>left-to-right</span></span><span>或者</span><span style="color:red"><span>right-to-left</span></span><span>的方式预训练模型，而</span><span style="color:#2196f3;font-weight:bold"><span>Bidirectional RNN网络</span></span><span>能够捕获上下文信息，每个单词能够间接的“see itself”，使得模型可在多层上下文中预测目标词。</span></p><p><span>为训练深度表征语言模型，BERT随机mask一定百分比的tokens，然后基于上下文预测这些被mask的tokens，这种过程称为“</span><span style="color:blue; font-family:Whitney"><span>masked LM</span></span><span>”（MLM），类似于</span><span style="border-bottom: 2px dashed FireBrick;"><span>完形填空</span></span><span>。</span></p><ul><li><p><span>训练过程中，将mask tokens在最后一层的隐状态接入softmax层，与标准LM处理方式一样，通过</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>最小化mask tokens的预测分布与实际分布的交叉熵</span></span><span>，</span><span style="border-bottom: 2px dashed FireBrick;"><span>优化语言模型</span></span><span>。BERT的所有试验中，随机mask 15%的tokens。</span></p><p><em><span>在这种设置下，被masked的token的隐藏向量表示被输出到词汇表的softmax上，这就与标准语言模型设置相同。</span></em></p></li><li><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>案例</span></kbd><span> 假设有这样一个句子：“</span><span style="border-bottom: 2px dashed FireBrick;"><span>我喜欢阅读Analytics Vidhya上的数据科学博客</span></span><span>”。想要训练一个双向的语言模型，可以建立一个模型来预测序列中的遗漏单词，而不是试图预测序列中的下一个单词。 </span></p><p><kbd style="background:yellow; color:red"><span>做法</span></kbd><span> 将“Analytics”替换为“[MASK]”，表示丢失的标记。然后，以这样的方式训练模型，使其能够预测“Analytics”是本句中遗漏的部分：“我喜欢阅读[MASK] Vidhya上的数据科学博客。”</span></p><p><strong style="color:red"><span>※</span></strong><span> 这是Masked Language Model的关键。BERT的开发者还提出了一些进一步改进该技术的注意事项: </span></p><ul><li><p><span>为了防止模型过于关注特定的位置或掩盖的标记，研究人员随机掩盖了15%的词。</span></p></li><li><p><span>掩盖的词并不总是被[MASK]替换，因为在微调时不会出现[MASK]。</span></p></li><li><p><span>因此，研究人员使用了以下方法：</span></p><ul><li><p><span>[MASK]替换的概率为80%</span></p></li><li><p><span>随机词替换的概率为10%</span></p></li><li><p><span>不进行替换的概率为10%</span></p></li></ul></li></ul></li></ul><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>问题</span></kbd><span> </span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>Masked LM如何用于下游任务的Fine-tuning?</span></span></p><p><span>Mask tokens方法可有效预训练</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>双向深层语言模型</span></span><span>，然而实际fine-tuning过程中不存在[MASK] token，造成预训练模型和fine-tuning</span><strong style="color:red"><span>不匹配</span></strong><span>。</span></p><p><em><span>Masked LM预训练任务的缺点在于</span><span style="border-bottom: 2px dashed FireBrick;"><span>由于</span><code>[MASK]</code><span>标记不会出现在微调阶段，这就造成了预训练和微调阶段的不一致</span></span><span>。</span></em></p><ul><li><p><span>为了解决这个问题，作者提出了一种折中的解决方案：</span></p><ul><li><p><span>随机选择15%的token，这些要被masked的token并不会真的全替换成[MASK]，而是从这些token中：</span></p><ul><li><p><span>随机选择80%替换成</span><code>[MASK]</code><span>；</span></p></li><li><p><span>随机选择10%替换成随机token；</span></p></li><li><p><span>随机选择10%不改变原token。</span></p></li></ul><p><span>然后， </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.266ex" height="1.871ex" role="img" focusable="false" viewBox="0 -677 1001.6 827" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.339ex;"><defs><path id="MJX-546-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-546-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mstyle" fill="#990000" stroke="#990000"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="54" xlink:href="#MJX-546-TEX-N-54"></use></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><use data-c="69" xlink:href="#MJX-546-TEX-N-69"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mstyle mathcolor="#990000"><msub><mi mathvariant="normal">T</mi><mi mathvariant="normal">i</mi></msub></mstyle></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{\textcolor{#990000}{T_i}}</script><span> 使用交叉熵损失来预测原始的token。</span></p></li></ul></li></ul><p><span>BERT为</span><strong style="color:red"><span>匹配</span></strong><span>pre-trained model和fine-tuning，对于已经确定需要mask的tokens，BERT</span><span style="color:red"><span>不总将这些“被选中”的tokens替换为[MASK]</span></span><span>，而是将其中80%会被替换为[MASK]、10%随机替换为其他token（1.5%）、10%不做改变，</span><strong><mark><span>使得预训练阶段中也具有没有mask的输入，匹配预训练和微调</span></mark></strong><span>。</span></p><center>	<hr style="border-bottom: dashed 1px red; width:70%"></center><p><span>对一个输入的词元序列，如果一个词元是</span><span style="color:#2196f3;font-weight:bold"><span>由WordPiece生成的话</span></span><span>（也就是切开来的），那就会有15%的概率</span><span style="color:#2196f3;font-weight:bold"><span>随机替换成一个掩码</span></span><code>[MASK]</code><span>。</span></p><p><em><span>ps</span></em><span>：（当然，对于</span><code>[CLS]</code><span>和</span><code>[SEP]</code><span>就不做替换了，这属于功能性的）</span></p><p><span>整体来看，如果输入序列是1000的话，那就要预测大约150个词。</span></p><ul><li><p><span>当然，这一过程是</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>MLM预训练</span></span><span style="border-bottom: 2px dashed FireBrick;"><span>独有的</span></span><span>，在微调的过程中是看不到这一个过程的，更看不到</span><code>[MASK]</code><span>。</span></p></li><li><p><span>但是，这个</span><span style="color:#2196f3;font-weight:bold"><span>替换</span></span><span>的过程，也不是100%替换成</span><code>[MASK]</code><span>的，具体来说是这样的方案：</span></p><ul><li><p><span>80%：替换为</span><code>[MASK]</code></p></li><li><p><span>10%：替换为</span><code>一个随机的词元</code></p></li><li><p><span>10%：什么都不做，但是用来做预测</span></p></li></ul></li></ul><blockquote><p><span>附录的一个例子：</span></p><p><strong><span>Masked LM and the Masking Procedure</span></strong></p><p><span>Assuming the unlabeled sentence is </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is hairy</span></span><span>, and during the random masking procedure we chose the 4-th token (which corresponding to </span><span style="color:blue; font-family:Comic Sans MS"><span>hairy</span></span><span>), our masking procedure can be further illustrated by</span></p><ul><li><p><span>80% of the time: Replace the word with the </span><code>[MASK]</code><span> token, e.g., </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is hairy</span></span><span> </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-549-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-549-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo accent="false" stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\to</script><span> </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is </span><code>[MASK]</code></span></p></li><li><p><span>10% of the time: Replace the word with a random word, e.g., </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is hairy</span></span><span> </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-549-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-549-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo accent="false" stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\to</script><span> </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is </span><code>apple</code></span></p></li><li><p><span>10% of the time: Keep the word un-changed, e.g., </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is hairy</span></span><span> </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-549-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-549-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo accent="false" stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\to</script><span> </span><span style="color:blue; font-family:Comic Sans MS"><span>my dog is hairy</span></span><span>. The purpose of this is to bias the representation towards the actual observed word.</span></p></li></ul></blockquote><div style="
    border-radius: 25px; 
    border: 2px solid #990000;
    padding: 20px;
            "><center><mark style="background:#f8e272;">MLM与NSP之间的关系</mark></center><strong style="color:red">※</strong> Masked Language Model是为了理解<span style="color:red">词之间的关系</span>。<br/><strong style="color:red">※</strong> BERT还接受了Next Sentence Prediction训练，来理解<span style="color:blue">句子之间的关系</span>。 </div><h4 id='任务2句子匹配next-sentence-prediction-nsp）'><span>任务2：句子匹配（Next Sentence Prediction, NSP）</span></h4><p><code>[原因]</code><span>很多下游任务都是基于对两句话之间的关系的理解，语言模型不能直接捕获这种信息。为了训练模型理解这种句间关系，作者设计了next sentence prediction的二分类任务。</span></p><p><code>[原因]</code><span>为处理依赖不同句子关联关系的下游任务，如Question Answering(QA)和Natural Language Inference(NLI)，BERT</span><span style="color:blue; font-family:仿宋; font-weight:bold"><span>预训练</span></span><span>sentence A是否是sentence B的下一句这种简单的二分类任务（是/否：二分类）。</span></p><ul><li><p><span>具体来说：选择两个句子(sentence A 和 sentence B)作为训练数据，有50%的概率：B是A的下一句（isNEXT），有50%的概率：A和B是从语料库中随机选择的句子对（NotNext），图1中 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.05ex;"><defs><path id="MJX-560-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-560-TEX-I-1D436"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">C</script><span> 用于next sentence prediction（NSP），预测将</span><code>[CLS]</code><span>的最终隐状态 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.633ex" height="1.643ex" role="img" focusable="false" viewBox="0 -705 722 726" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.048ex;"><defs><path id="MJX-551-TEX-N-43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mstyle" fill="#990000" stroke="#990000"><g data-mml-node="mi"><use data-c="43" xlink:href="#MJX-551-TEX-N-43"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mstyle mathcolor="#990000"><mi mathvariant="normal">C</mi></mstyle></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{\textcolor{#990000}{C}}</script><span> 输入sigmoid实现。尽管这种模型非常简单，但可</span><span style="border-bottom: 2px dashed FireBrick;"><span>十分有效地应用于具有句子级别关联关系的下游任务</span></span><span>。</span></p><center>	<hr style="border-bottom: dashed 1px red; width:70%"></center><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>实例理解</span></kbd><span> 假设有一个包含100,000个句子的文本数据集。因此，将有5万个训练样本或句子对作为训练数据。 </span></p><ul><li><p><span>其中50%的句子对的第二句就是第一句的下一句。</span></p></li><li><p><span>剩余50%的句子对，第二句从语料库中随机抽取。</span></p></li><li><p><span>第一种情况的标签为‘IsNext’ ；第二种情况的标签为‘NotNext’。</span></p></li></ul><center>	<hr style="border-bottom: dashed 1px red; width:70%"></center></li><li><p><span>Pre-training data（预训练数据）</span></p><ul><li><p><span>作者选用了BooksCorpus（800M words）和English Wikipedia（2,500M words）作为预训练的语料库，作者只选取了Wikipedia中的文本段落，忽略了表格、标题等。为了获取长的连续文本序列，作者选用了Billion Word Benchmark这样的文档级语料库，而非打乱的句子级语料库。</span></p><ul><li><p><span>BERT的预训练是在包含整个维基百科的无标签号文本的大语料库中（足足有25亿字！） 和图书语料库（有8亿字）中进行的。</span></p></li></ul></li></ul></li></ul><p><span style="border-bottom: 2px dashed FireBrick;"><span>NSP任务</span></span><span>与一些研究人员提出的</span><span style="border-bottom: 2px dashed FireBrick;"><span>表征学习（Representation Learning）</span></span><span>很相似，</span><strong><span>一些表征学习模型</span></strong><span>（feature-based）仅将</span><span style="color:red"><span>句嵌入</span></span><span>用于下游任务，BERT是将</span><span style="color:red; font-weight:bold"><span>所有预训练的参数</span></span><span>用于下游任务（fine-tuning）。</span></p><blockquote><p><span style="color:blue; font-family:楷体; font-weight:bold; font-size:20px"><span>理解特殊Token的意义（BERT的两个任务）</span></span></p><p><strong style="color:red"><span>※</span></strong><span> BERT在输入序列头部添加</span><code>[CLS]</code><span> token，不同句子间添加</span><code>[SEP]</code><span> token，掩盖词替换为</span><code>[MASK]</code><span> token。</span></p><ul><li><p><span>在预训练“</span><strong><span>下句预测</span></strong><span>”任务时，</span><span style="border-bottom: 2px dashed FireBrick;"><span>使用</span><code>[CLS]</code><span> token在最后一层的隐状态用于预测类别</span></span><span>，</span><span style="color:blue"><span>通过训练使得从上（输出侧）至下（输入侧）的网络结构可用于分类任务</span></span><span>，分类任务中输出侧仅使用</span><code>[CLS]</code><span> token对应的隐状态。对应的</span><code>[SEP]</code><span> token，BERT也能学习到其他代表连接不同句子。</span></p></li></ul><ul><li><p><span>在预训练“</span><strong><span>完形填空</span></strong><span>”任务时，</span><span style="border-bottom: 2px dashed FireBrick;"><span>使用</span><code>[MASK]</code><span> token在最后一层的隐状态用于预测真实词</span></span><span>，</span><span style="color:blue"><span>通过训练使得不同输出位置具有语义表征能力</span></span><span>。</span></p></li></ul><p>❗️<span> </span><em><span>看到没有，这两个任务好像可以同时训练，即在NSP任务中随机mask一些词，</span><span style="color:red"><span>牛轰轰</span></span><span>！！！</span></em></p></blockquote><p>&nbsp;</p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>这就是BERT为什么能够成为一个真正的任务无关模型。因为它结合了Masked Language Model (MLM)和Next Sentence Prediction (NSP)的预训练任务。</span></span></p><p>&nbsp;</p><p><span>无论是在QA还是语言推理层面，都是一个句子对，所以最好让其学习一些句子层面的信息。</span></p><p><span>对于句子A和B，有可能是相邻，也有可能不是：</span></p><ul><li><p><span>那么相邻的就是正例；</span></p></li><li><p><span>不相邻的就是负例。</span></p><p><span>各占50%。</span></p></li></ul><blockquote><p><span>附录的一个例子：</span></p><p><strong><span>Next Sentence Prediction</span></strong></p><p><span>The next sentence prediction task can be illustrate in the following examples.</span></p><p><strong><span>Input</span></strong><span> = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</span></p><p><strong><span>Label</span></strong><span> = IsNext</span></p><p><strong><span>Input</span></strong><span> = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight </span><span style="color:red"><span>##</span></span><span>less birds [SEP]</span></p><p><strong><span>Label</span></strong><span> = NotNext</span></p></blockquote><p><span>值得一提的是，可以看到有一个</span><code>##</code><span>，这个意思是说：</span><code>flightless</code><span>这个词在原文中不常见，所以砍成了两个词，</span><code>##</code><span>的作用是表明这原本是一个词。</span></p><p>&nbsp;</p><p><strong style="color:red"><span>※</span></strong><span> 两种不同策略的预训练精度结果（MLM &amp; LR）：</span></p><p><img src=".\pp003_files\image-20240813172101186.png" alt="image-20240813172101186" style="border-radius:10px; border:1px solid #ab0000;"/></p><p>&nbsp;</p><h4 id='再看微调'><span>再看微调</span></h4><p><span>BERT基于Transformer的self-attention机制（不同位置词的距离都是1，语意表征能力强）预训练模型，可基于fine-tuning所有参数处理多数下游任务。</span></p><p><span>因为Transformer中的self-attention机制适用于很多下游任务，所以可以直接对模型进行微调。对于涉及文本对的任务，一般的做法是</span><span style="border-bottom: 2px dashed FireBrick;"><kbd style="background:#f8e272"><span>1</span></kbd><span> 独立 encode 文本对，</span><kbd style="background:#a8e195"><span>2</span></kbd><span> 然后再应用双向的cross attention进行交互</span></span><span>。BERT使用self-Attenton机制统一了这</span><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>两个阶段</span></span><span>，该机制直接能够实现两个串联句子的交叉编码。</span><span style="color:#990000">😧<span> 不明白2024年8月14日 19:36:37</span></span></p><p><span>对于不同的任务，只需要简单地将特定于该任务的</span><span style="border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red; font-weight:bold"><span>输入</span></span><span style="border-top: 2px solid black; border-bottom: 2px solid black; border-left: 2px solid black; border-right: 2px solid black; color:red; font-weight:bold"><span>输出</span></span><span>插入到BERT中，然后进行端到端的微调（end2end fine-tuning）。</span></p><ul><li><p><span>对于</span><span style="border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red; font-weight:bold"><span>输入</span></span><span>，预训练中的sentence A 和sentence B</span><span style="color:#2196f3;font-weight:bold"><span>能够替换成</span></span><span>：</span></p><ul><li><p><span>同义关系中的句子对；</span></p></li><li><p><span>蕴含关系中的“假设-前提”对；</span></p></li><li><p><span>问答中的“段落-问题”对；</span></p></li><li><p><span>文本分类或序列标注中的“文本-null”。</span></p></li></ul></li><li><p><span>对于</span><span style="border-top: 2px solid black; border-bottom: 2px solid black; border-left: 2px solid black; border-right: 2px solid black; color:red; font-weight:bold"><span>输出</span></span><span>：</span></p><ul><li><p><span>对于token-level的任务，如序列标注、问答，将BERT输出的token编码输入到输出层；</span></p></li><li><p><span>对于sentence-level的任务，如句子的蕴含关系、情感分析等，将</span><code>[CLS]</code><span>作为输入序列的聚合编码，输入到输出层。</span></p><p><span style="color:#990000">😧<span> 不明白2024年8月14日 19:36:37</span></span></p></li></ul></li></ul><p><img src=".\pp003_files\image-20240814111559751.png" alt="image-20240814111559751" style="zoom:50%;" /></p><blockquote><ul><li><p><span style="border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red; font-weight:bold"><span>[CLS]输入</span></span><span>对应</span><span style="color:red"><span>输出层的隐状态</span></span><span>用于</span><span style="border-bottom: 2px dashed FireBrick;"><span>分类任务</span></span><span>；</span></p></li><li><p><span style="border-top: 2px solid red; border-bottom: 2px solid red; border-left: 2px solid red; border-right: 2px solid red; font-weight:bold"><span>其他输入</span></span><span>对应</span><span style="color:red"><span>输出层的隐状态</span></span><span>用于</span><span style="border-bottom: 2px dotted FireBrick;"><span>序列标注或问答等任务</span></span><span>。</span></p></li></ul></blockquote><p>&nbsp;</p><p><span>由于选择了单一个编码器的架构，而不是像传统的Transformer一样有编码器和解码器，所以会有一些缺点：</span></p><ul><li><p><span>与GPT比，</span><span style="color:red"><span>BERT用的是编码器</span></span><span>，</span><span style="color:blue"><span>GPT用的是解码器</span></span><span>。</span></p></li><li><p><span>BERT做机器翻译、文本的摘要，也就是生成类的任务并不好做。</span></p></li></ul><p><span>不过事实上，分类问题在NLP中更常见。</span></p><blockquote><p><span>如下图是BERT在分类任务上的表现情况：</span></p><p><img src=".\pp003_files\image-20240813172535757.png" referrerpolicy="no-referrer" alt="image-20240813172535757"></p></blockquote><p>&nbsp;</p><h3 id='实验'><span>实验</span></h3><p><span>BERT在11项NLP任务的微调结果。</span></p><ul><li><p><span style="color:blue; font-family:Whitney"><span>GLUE</span></span></p><ul><li><p><strong><span>G</span></strong><span>eneral </span><strong><span>L</span></strong><span>anguage </span><strong><span>U</span></strong><span>ndestanding </span><strong><span>E</span></strong><span>valuation(</span><strong><span>GLUE</span></strong><span>) benchmark is collection of </span><span style="color:#b000e0;font-weight:bold"><span>diverse natural language understanding</span></span><span> tasks.</span></p><p><strong><span>通用语言理解评价</span></strong><span>(GLUE)基准是多种自然语言理解任务的集合。</span></p><p><span>GLUE是多个 NLP 任务的集合。</span></p></li><li><p><span>Fine-tuning（微调）：</span></p><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red;"><span>作者设置 batch size 为 32；训练 3 个 epochs；在验证集上从（5e-5, 4e-5, 3e-5, 2e-5）中选择最优的学习率。</span></span></p><ul><li><p><span>最后隐藏层向量 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="7.507ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 3317.9 886" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.09ex;"><defs><path id="MJX-552-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJX-552-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-552-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-552-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-552-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(1037.8,0)"><use data-c="2208" xlink:href="#MJX-552-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(1982.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-552-TEX-D-211D"></use></g></g><g data-mml-node="TeXAtom" transform="translate(755,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="48" xlink:href="#MJX-552-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">H</mi></mrow></msup></math></mjx-assistive-mml></mjx-container><script type="math/tex">C \in \mathbb{R}^\mathrm{H}</script><span> 对应于第一层输入token </span><code>[CLS]</code><span>作为聚合表征；</span></p></li><li><p><span>分类层权重 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="10.647ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 4706.1 886" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.09ex;"><defs><path id="MJX-553-TEX-I-1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path><path id="MJX-553-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-553-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-553-TEX-N-4B" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H313Q235 637 233 620Q232 618 232 462L233 307L379 449Q425 494 479 546Q518 584 524 591T531 607V608Q531 630 503 636Q501 636 498 636T493 637H489V683H499Q517 680 630 680Q704 680 716 683H722V637H708Q633 633 589 597Q584 592 495 506T406 419T515 254T631 80Q644 60 662 54T715 46H736V0H728Q719 3 615 3Q493 3 472 0H461V46H469Q515 46 515 72Q515 78 512 84L336 351Q332 348 278 296L232 251V156Q232 62 235 58Q243 47 302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path><path id="MJX-553-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-553-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D44A" xlink:href="#MJX-553-TEX-I-1D44A"></use></g><g data-mml-node="mo" transform="translate(1325.8,0)"><use data-c="2208" xlink:href="#MJX-553-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(2270.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-553-TEX-D-211D"></use></g></g><g data-mml-node="TeXAtom" transform="translate(755,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="4B" xlink:href="#MJX-553-TEX-N-4B"></use></g><g data-mml-node="mo" transform="translate(778,0)"><use data-c="D7" xlink:href="#MJX-553-TEX-N-D7"></use></g><g data-mml-node="mi" transform="translate(1556,0)"><use data-c="48" xlink:href="#MJX-553-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">K</mi><mo>×</mo><mi mathvariant="normal">H</mi></mrow></msup></math></mjx-assistive-mml></mjx-container><script type="math/tex">W \in \mathbb{R}^\mathrm{K\times H}</script><span> 只是在微调过程中的新参数，</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.011ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 889 683" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: 0px;"><defs><path id="MJX-452-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D43E" xlink:href="#MJX-452-TEX-I-1D43E"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">K</script><span> 是标签的数量；</span></p></li><li><p><span>损失函数（Loss function）是：</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="18.325ex" height="2.47ex" role="img" focusable="false" viewBox="0 -841.7 8099.5 1091.7" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.566ex;"><defs><path id="MJX-554-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-554-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-554-TEX-N-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path id="MJX-554-TEX-N-A0" d=""></path><path id="MJX-554-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-554-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-554-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-554-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-554-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-554-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path id="MJX-554-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-554-TEX-N-43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path><path id="MJX-554-TEX-N-57" d="M792 683Q810 680 914 680Q991 680 1003 683H1009V637H996Q931 633 915 598Q912 591 863 438T766 135T716 -17Q711 -22 694 -22Q676 -22 673 -15Q671 -13 593 231L514 477L435 234Q416 174 391 92T358 -6T341 -22H331Q314 -21 310 -15Q309 -14 208 302T104 622Q98 632 87 633Q73 637 35 637H18V683H27Q69 681 154 681Q164 681 181 681T216 681T249 682T276 683H287H298V637H285Q213 637 213 620Q213 616 289 381L364 144L427 339Q490 535 492 546Q487 560 482 578T475 602T468 618T461 628T449 633T433 636T408 637H380V683H388Q397 680 508 680Q629 680 650 683H660V637H647Q576 637 576 619L727 146Q869 580 869 600Q869 605 863 612T839 627T794 637H783V683H792Z"></path><path id="MJX-554-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-554-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="6C" xlink:href="#MJX-554-TEX-N-6C"></use><use data-c="6F" xlink:href="#MJX-554-TEX-N-6F" transform="translate(278,0)"></use><use data-c="67" xlink:href="#MJX-554-TEX-N-67" transform="translate(778,0)"></use></g><g data-mml-node="mtext" transform="translate(1278,0)"><use data-c="A0" xlink:href="#MJX-554-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(1528,0)"><use data-c="73" xlink:href="#MJX-554-TEX-N-73"></use><use data-c="6F" xlink:href="#MJX-554-TEX-N-6F" transform="translate(394,0)"></use><use data-c="66" xlink:href="#MJX-554-TEX-N-66" transform="translate(894,0)"></use><use data-c="74" xlink:href="#MJX-554-TEX-N-74" transform="translate(1200,0)"></use><use data-c="6D" xlink:href="#MJX-554-TEX-N-6D" transform="translate(1589,0)"></use><use data-c="61" xlink:href="#MJX-554-TEX-N-61" transform="translate(2422,0)"></use><use data-c="78" xlink:href="#MJX-554-TEX-N-78" transform="translate(2922,0)"></use></g><g data-mml-node="mo" transform="translate(4978,0)"><use data-c="28" xlink:href="#MJX-554-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(5367,0)"><use data-c="43" xlink:href="#MJX-554-TEX-N-43"></use></g><g data-mml-node="msup" transform="translate(6089,0)"><g data-mml-node="mi"><use data-c="57" xlink:href="#MJX-554-TEX-N-57"></use></g><g data-mml-node="mi" transform="translate(1061,363) scale(0.707)"><use data-c="54" xlink:href="#MJX-554-TEX-N-54"></use></g></g><g data-mml-node="mo" transform="translate(7710.5,0)"><use data-c="29" xlink:href="#MJX-554-TEX-N-29"></use></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">log</mi><mtext>&nbsp;</mtext><mi data-mjx-auto-op="false">softmax</mi><mo stretchy="false">(</mo><mi mathvariant="normal">C</mi><msup><mi mathvariant="normal">W</mi><mi mathvariant="normal">T</mi></msup><mo stretchy="false">)</mo></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{log \ softmax(C W ^ T)}</script></p></li><li><p><span>超参数（Hyper parameters）：batch_size=32, epochs=2, learning rate among 5e-5~2e-5</span></p></li><li><p><span>对于</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="10.011ex" height="2.214ex" role="img" focusable="false" viewBox="0 -683 4424.8 978.7" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.669ex;"><defs><path id="MJX-555-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-555-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-555-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-555-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-555-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-555-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-555-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-555-TEX-N-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path id="MJX-555-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="42" xlink:href="#MJX-555-TEX-N-42"></use><use data-c="45" xlink:href="#MJX-555-TEX-N-45" transform="translate(708,0)"></use><use data-c="52" xlink:href="#MJX-555-TEX-N-52" transform="translate(1389,0)"></use><use data-c="54" xlink:href="#MJX-555-TEX-N-54" transform="translate(2125,0)"></use></g><g data-mml-node="TeXAtom" transform="translate(2880,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="6C" xlink:href="#MJX-555-TEX-N-6C"></use><use data-c="61" xlink:href="#MJX-555-TEX-N-61" transform="translate(278,0)"></use><use data-c="72" xlink:href="#MJX-555-TEX-N-72" transform="translate(778,0)"></use><use data-c="67" xlink:href="#MJX-555-TEX-N-67" transform="translate(1170,0)"></use><use data-c="65" xlink:href="#MJX-555-TEX-N-65" transform="translate(1670,0)"></use></g></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><msub><mi data-mjx-auto-op="false">BERT</mi><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">large</mi></mrow></msub></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{BERT_{large}}</script><span>而言，小数据集有时候可能是不够稳定的，在Dec集上通过运行几个随机开始选择最好的模型？？（不懂）</span></p></li></ul></li></ul><p><span>结果如下：</span></p><p><img src=".\pp003_files\image-20240814193932003.png" referrerpolicy="no-referrer" alt="image-20240814193932003"></p></li><li><p><span style="color:blue; font-family:Whitney"><span>SQuAD v1.1</span></span></p><ul><li><p><strong><span>S</span></strong><span>tanford </span><strong><span>Qu</span></strong><span>estion </span><strong><span>A</span></strong><span>nswering </span><strong><span>D</span></strong><span>ataset. Given a question and a passage from Wikipedia containing the answer, the task is to </span><span style="color:#b000e0;font-weight:bold"><span>predict the answer text span in the passage</span></span><span>.</span></p><p><span>斯坦福问答数据集。给定一个问题和一个从维基百科摘录的包含该问题答案的文章。任务就是来预测文章中答案文本的范围。</span></p></li><li><p><span>Fine-tuning（微调）：</span></p><ul><li><p><span>表示输入句子（嵌入A）和文章（嵌入B）作为一个单个打包的句子；</span></p></li><li><p><span>引入一个开始向量 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="7.045ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 3113.9 886" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.09ex;"><defs><path id="MJX-556-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path id="MJX-556-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-556-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-556-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="53" xlink:href="#MJX-556-TEX-N-53"></use></g><g data-mml-node="mo" transform="translate(833.8,0)"><use data-c="2208" xlink:href="#MJX-556-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(1778.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-556-TEX-D-211D"></use></g></g><g data-mml-node="mi" transform="translate(755,363) scale(0.707)"><use data-c="48" xlink:href="#MJX-556-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">S</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mi mathvariant="normal">H</mi></msup></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{S \in \mathbb{R}^H}</script><span> 和一个结束向量  </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="7.328ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 3238.9 886" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.09ex;"><defs><path id="MJX-557-TEX-N-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path><path id="MJX-557-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-557-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-557-TEX-N-48" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="45" xlink:href="#MJX-557-TEX-N-45"></use></g><g data-mml-node="mo" transform="translate(958.8,0)"><use data-c="2208" xlink:href="#MJX-557-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(1903.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-557-TEX-D-211D"></use></g></g><g data-mml-node="mi" transform="translate(755,363) scale(0.707)"><use data-c="48" xlink:href="#MJX-557-TEX-N-48"></use></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">E</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="double-struck">R</mi></mrow><mi mathvariant="normal">H</mi></msup></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{E \in \mathbb{R}^H}</script><span> ；</span></p></li><li><p><span>第 i 个答案区间的开始单词（结束单词类似）的概率是：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n1424" cid="n1424" mdtype="math_block" data-math-tag-before="1" data-math-tag-after="2" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 29.729ex; position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="5.881ex" role="img" focusable="false" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -2.375ex; min-width: 29.729ex;"><defs><path id="MJX-830-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-830-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-830-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-830-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-830-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-830-TEX-I-1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJX-830-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-830-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-830-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-830-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-830-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-830-TEX-SO-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path id="MJX-830-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-830-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.019382,-0.019382) translate(0, -1549.8)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1549.8) matrix(1 0 0 -1 0 0) scale(51.6)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="4492.1 -1549.8 1 2599.6"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,89.8)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D443" xlink:href="#MJX-830-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(675,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-830-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(1246.7,0)"><use data-c="3D" xlink:href="#MJX-830-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(2302.5,0)"><g data-mml-node="mrow" transform="translate(1042.2,710)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-830-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(466,0)"><use data-c="1D465" xlink:href="#MJX-830-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(1038,0)"><use data-c="1D45D" xlink:href="#MJX-830-TEX-I-1D45D"></use></g><g data-mml-node="mo" transform="translate(1541,0)"><use data-c="28" xlink:href="#MJX-830-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1930,0)"><use data-c="1D446" xlink:href="#MJX-830-TEX-I-1D446"></use></g><g data-mml-node="mo" transform="translate(2797.2,0)"><use data-c="22C5" xlink:href="#MJX-830-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(3297.4,0)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-830-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-830-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(4208.4,0)"><use data-c="29" xlink:href="#MJX-830-TEX-N-29"></use></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-830-TEX-SO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-830-TEX-I-1D457"></use></g></g></g><g data-mml-node="mi" transform="translate(1597,0)"><use data-c="1D452" xlink:href="#MJX-830-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2063,0)"><use data-c="1D465" xlink:href="#MJX-830-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(2635,0)"><use data-c="1D45D" xlink:href="#MJX-830-TEX-I-1D45D"></use></g><g data-mml-node="mo" transform="translate(3138,0)"><use data-c="28" xlink:href="#MJX-830-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(3527,0)"><use data-c="1D446" xlink:href="#MJX-830-TEX-I-1D446"></use></g><g data-mml-node="mo" transform="translate(4394.2,0)"><use data-c="22C5" xlink:href="#MJX-830-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(4894.4,0)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-830-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><use data-c="1D457" xlink:href="#MJX-830-TEX-I-1D457"></use></g></g><g data-mml-node="mo" transform="translate(5852.8,0)"><use data-c="29" xlink:href="#MJX-830-TEX-N-29"></use></g></g><rect width="6441.8" height="60" x="120" y="220"></rect></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1549.8 1 2599.6"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:2" transform="translate(0,839.8)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><use data-c="28" xlink:href="#MJX-830-TEX-N-28"></use><use data-c="32" xlink:href="#MJX-830-TEX-N-32" transform="translate(389,0)"></use><use data-c="29" xlink:href="#MJX-830-TEX-N-29" transform="translate(889,0)"></use></g></g></g></g></svg></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(2)</mtext></mtd><mtd><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>S</mi><mo>⋅</mo><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></munder><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>S</mi><mo>⋅</mo><msub><mi>T</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></div></div></li><li><p><span>候选区域从位置 i 到位置 j 是：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n1427" cid="n1427" mdtype="math_block" data-math-tag-before="2" data-math-tag-after="3" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 34.083ex; position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="2.363ex" role="img" focusable="false" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.616ex; min-width: 34.083ex;"><defs><path id="MJX-831-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-831-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-831-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-831-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-831-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-831-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-831-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path><path id="MJX-831-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-831-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-831-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-831-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-831-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-831-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-831-TEX-I-1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path><path id="MJX-831-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-831-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-831-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.019382,-0.019382) translate(0, -772.1)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 772.1) matrix(1 0 0 -1 0 0) scale(51.6)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="5454.3 -772.1 1 1044.2"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr" transform="translate(0,22.1)"><g data-mml-node="mtd"><g data-mml-node="mi"><use data-c="1D460" xlink:href="#MJX-831-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(469,0)"><use data-c="1D450" xlink:href="#MJX-831-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(902,0)"><use data-c="1D45C" xlink:href="#MJX-831-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(1387,0)"><use data-c="1D45F" xlink:href="#MJX-831-TEX-I-1D45F"></use></g><g data-mml-node="msub" transform="translate(1838,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-831-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-831-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="2192" xlink:href="#MJX-831-TEX-N-2192"></use></g><g data-mml-node="mi" transform="translate(1345,0)"><use data-c="1D457" xlink:href="#MJX-831-TEX-I-1D457"></use></g></g></g><g data-mml-node="mo" transform="translate(3907.2,0)"><use data-c="3D" xlink:href="#MJX-831-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(4962.9,0)"><use data-c="1D446" xlink:href="#MJX-831-TEX-I-1D446"></use></g><g data-mml-node="mo" transform="translate(5830.2,0)"><use data-c="22C5" xlink:href="#MJX-831-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(6330.4,0)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-831-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-831-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(7463.6,0)"><use data-c="2B" xlink:href="#MJX-831-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(8463.8,0)"><use data-c="1D438" xlink:href="#MJX-831-TEX-I-1D438"></use></g><g data-mml-node="mo" transform="translate(9450,0)"><use data-c="22C5" xlink:href="#MJX-831-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(9950.2,0)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-831-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><use data-c="1D457" xlink:href="#MJX-831-TEX-I-1D457"></use></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -772.1 1 1044.2"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:3" transform="translate(0,772.1)"><text data-id-align="true"></text><g data-idbox="true" transform="translate(0,-750)"><g data-mml-node="mtext"><use data-c="28" xlink:href="#MJX-831-TEX-N-28"></use><use data-c="33" xlink:href="#MJX-831-TEX-N-33" transform="translate(389,0)"></use><use data-c="29" xlink:href="#MJX-831-TEX-N-29" transform="translate(889,0)"></use></g></g></g></g></svg></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(3)</mtext></mtd><mtd><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow data-mjx-texclass="ORD"><mi>i</mi><mo accent="false" stretchy="false">→</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>S</mi><mo>⋅</mo><msub><mi>T</mi><mi>i</mi></msub><mo>+</mo><mi>E</mi><mo>⋅</mo><msub><mi>T</mi><mi>j</mi></msub></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></div></div></li><li><p><span>训练目标是正确开始和结束位置的对数似然的和（sum of log-likehood）。</span></p></li></ul><blockquote><p><span>微调思想：真实范围值尽可能大，非真实范围值尽可能小。</span></p></blockquote></li></ul></li><li><p><span style="color:blue; font-family:Whitney"><span>SQuAD v2.0</span></span></p><ul><li><p><span>SQuAD v2.0 extends the SQuAD v1.1 problem definition by allowing for the possibility that </span><span style="color:#b000e0;font-weight:bold"><span>no short answer exists</span></span><span> in the provided paragraph, making the problem more realistic.</span></p><p><span>SQuAD v2.0扩展了SQuAD v1.1问题定义，通过允许</span><span style="color:#b000e0;font-weight:bold"><span>没有短答案存在</span></span><span>于提供的段落中的可能性，使得问题更加现实。</span></p></li><li><p><span>Fine-tuning（微调）：</span></p><ul><li><p><span>基于SQuAD v1.1 BERT模型；</span></p></li><li><p><span>对待问题（没有在[CLS] token具有开始or结束的答案区间），对比没有答案区间的分数和最佳没有答案区间</span><span style="color:red"><span>（不知所云</span>😱<span>）</span></span><span>：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n1445" cid="n1445" mdtype="math_block" data-math-tag-before="3" data-math-tag-after="4" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 38.56ex; position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="6.787ex" role="img" focusable="false" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -2.828ex; min-width: 38.56ex;"><defs><path id="MJX-832-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-832-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-832-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-832-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-832-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-832-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-832-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-832-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJX-832-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-832-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-832-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-832-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJX-832-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-832-TEX-I-1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path><path id="MJX-832-TEX-N-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJX-832-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-832-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path><path id="MJX-832-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-832-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-832-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-832-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-832-TEX-N-2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJX-832-TEX-N-2061" d=""></path><path id="MJX-832-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-832-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-832-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-832-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.019382,-0.019382) translate(0, -1749.8)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 1749.8) matrix(1 0 0 -1 0 0) scale(51.6)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="6443.8 -1749.8 1 2999.6"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr"><g data-mml-node="mtd"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,999.8)"><g data-mml-node="mtd"></g><g data-mml-node="mtd"><g data-mml-node="mi"><use data-c="1D460" xlink:href="#MJX-832-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(469,0)"><use data-c="1D450" xlink:href="#MJX-832-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(902,0)"><use data-c="1D45C" xlink:href="#MJX-832-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(1387,0)"><use data-c="1D45F" xlink:href="#MJX-832-TEX-I-1D45F"></use></g><g data-mml-node="msub" transform="translate(1838,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-832-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-832-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(600,0)"><use data-c="1D462" xlink:href="#MJX-832-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1172,0)"><use data-c="1D459" xlink:href="#MJX-832-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(1470,0)"><use data-c="1D459" xlink:href="#MJX-832-TEX-I-1D459"></use></g></g></g><g data-mml-node="mo" transform="translate(3914.9,0)"><use data-c="3D" xlink:href="#MJX-832-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(4970.7,0)"><use data-c="1D446" xlink:href="#MJX-832-TEX-I-1D446"></use></g><g data-mml-node="mo" transform="translate(5837.9,0)"><use data-c="22C5" xlink:href="#MJX-832-TEX-N-22C5"></use></g><g data-mml-node="mi" transform="translate(6338.2,0)"><use data-c="1D436" xlink:href="#MJX-832-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(7320.4,0)"><use data-c="2B" xlink:href="#MJX-832-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(8320.6,0)"><use data-c="1D438" xlink:href="#MJX-832-TEX-I-1D438"></use></g><g data-mml-node="mo" transform="translate(9306.8,0)"><use data-c="22C5" xlink:href="#MJX-832-TEX-N-22C5"></use></g><g data-mml-node="mi" transform="translate(9807.1,0)"><use data-c="1D436" xlink:href="#MJX-832-TEX-I-1D436"></use></g></g></g><g data-mml-node="mtr" transform="translate(0,-360.2)"><g data-mml-node="mtd"></g><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mrow"><g data-mml-node="mi"><use data-c="1D460" xlink:href="#MJX-832-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(469,0)"><use data-c="1D450" xlink:href="#MJX-832-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(902,0)"><use data-c="1D45C" xlink:href="#MJX-832-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(1387,0)"><use data-c="1D45F" xlink:href="#MJX-832-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1838,0)"><use data-c="1D452" xlink:href="#MJX-832-TEX-I-1D452"></use></g></g><g data-mml-node="mo" transform="translate(1152,16) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-832-TEX-N-5E"></use></g></g></g><g data-mml-node="TeXAtom" transform="translate(2337,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-832-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="2192" xlink:href="#MJX-832-TEX-N-2192"></use></g><g data-mml-node="mi" transform="translate(1345,0)"><use data-c="1D457" xlink:href="#MJX-832-TEX-I-1D457"></use></g></g></g><g data-mml-node="mo" transform="translate(3907.2,0)"><use data-c="3D" xlink:href="#MJX-832-TEX-N-3D"></use></g><g data-mml-node="munder" transform="translate(4962.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="OP"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-832-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(878,0)"><use data-c="1D44E" xlink:href="#MJX-832-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(1407,0)"><use data-c="1D465" xlink:href="#MJX-832-TEX-I-1D465"></use></g></g><g data-mml-node="TeXAtom" transform="translate(446.8,-645.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-832-TEX-I-1D457"></use></g><g data-mml-node="mo" transform="translate(412,0)"><use data-c="2265" xlink:href="#MJX-832-TEX-N-2265"></use></g><g data-mml-node="mi" transform="translate(1190,0)"><use data-c="1D456" xlink:href="#MJX-832-TEX-I-1D456"></use></g></g></g><g data-mml-node="mo" transform="translate(6941.9,0)"><use data-c="2061" xlink:href="#MJX-832-TEX-N-2061"></use></g><g data-mml-node="mi" transform="translate(6941.9,0)"><use data-c="1D446" xlink:href="#MJX-832-TEX-I-1D446"></use></g><g data-mml-node="mo" transform="translate(7809.2,0)"><use data-c="22C5" xlink:href="#MJX-832-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(8309.4,0)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-832-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-832-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(9442.6,0)"><use data-c="2B" xlink:href="#MJX-832-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(10442.8,0)"><use data-c="1D438" xlink:href="#MJX-832-TEX-I-1D438"></use></g><g data-mml-node="mo" transform="translate(11429,0)"><use data-c="22C5" xlink:href="#MJX-832-TEX-N-22C5"></use></g><g data-mml-node="msub" transform="translate(11929.2,0)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-832-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><use data-c="1D457" xlink:href="#MJX-832-TEX-I-1D457"></use></g></g></g></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -1749.8 1 2999.6"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:4"><g data-mml-node="mtext"><use data-c="28" xlink:href="#MJX-832-TEX-N-28"></use><use data-c="34" xlink:href="#MJX-832-TEX-N-34" transform="translate(389,0)"></use><use data-c="29" xlink:href="#MJX-832-TEX-N-29" transform="translate(889,0)"></use></g></g></g></svg></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(4)</mtext></mtd><mtd><mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt"><mtr><mtd></mtd><mtd><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow data-mjx-texclass="ORD"><mi>n</mi><mi>u</mi><mi>l</mi><mi>l</mi></mrow></msub><mo>=</mo><mi>S</mi><mo>⋅</mo><mi>C</mi><mo>+</mo><mi>E</mi><mo>⋅</mo><mi>C</mi></mtd></mtr><mtr><mtd></mtd><mtd><msub><mrow data-mjx-texclass="ORD"><mover><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo stretchy="false">^</mo></mover></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo accent="false" stretchy="false">→</mo><mi>j</mi></mrow></msub><mo>=</mo><munder><mrow data-mjx-texclass="OP"><mi>m</mi><mi>a</mi><mi>x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>j</mi><mo>≥</mo><mi>i</mi></mrow></munder><mo data-mjx-texclass="NONE">⁡</mo><mi>S</mi><mo>⋅</mo><msub><mi>T</mi><mi>i</mi></msub><mo>+</mo><mi>E</mi><mo>⋅</mo><msub><mi>T</mi><mi>j</mi></msub></mtd></mtr></mtable></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></div></div></li></ul><ul><li><p><span>预测一个非空答案，</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="23.393ex" height="2.498ex" role="img" focusable="false" viewBox="0 -810 10339.6 1104.2" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.666ex;"><defs><path id="MJX-558-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-558-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-558-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-558-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-558-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-558-TEX-N-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJX-558-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-558-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path><path id="MJX-558-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-558-TEX-N-3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path><path id="MJX-558-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-558-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-558-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJX-558-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-558-TEX-I-1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mrow"><g data-mml-node="mi"><use data-c="1D460" xlink:href="#MJX-558-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(469,0)"><use data-c="1D450" xlink:href="#MJX-558-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(902,0)"><use data-c="1D45C" xlink:href="#MJX-558-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(1387,0)"><use data-c="1D45F" xlink:href="#MJX-558-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1838,0)"><use data-c="1D452" xlink:href="#MJX-558-TEX-I-1D452"></use></g></g><g data-mml-node="mo" transform="translate(1152,16) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-558-TEX-N-5E"></use></g></g></g><g data-mml-node="TeXAtom" transform="translate(2337,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-558-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="2192" xlink:href="#MJX-558-TEX-N-2192"></use></g><g data-mml-node="mi" transform="translate(1345,0)"><use data-c="1D457" xlink:href="#MJX-558-TEX-I-1D457"></use></g></g></g><g data-mml-node="mo" transform="translate(3907.2,0)"><use data-c="3E" xlink:href="#MJX-558-TEX-N-3E"></use></g><g data-mml-node="mi" transform="translate(4962.9,0)"><use data-c="1D460" xlink:href="#MJX-558-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(5431.9,0)"><use data-c="1D450" xlink:href="#MJX-558-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(5864.9,0)"><use data-c="1D45C" xlink:href="#MJX-558-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(6349.9,0)"><use data-c="1D45F" xlink:href="#MJX-558-TEX-I-1D45F"></use></g><g data-mml-node="msub" transform="translate(6800.9,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-558-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-558-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(600,0)"><use data-c="1D462" xlink:href="#MJX-558-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1172,0)"><use data-c="1D459" xlink:href="#MJX-558-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(1470,0)"><use data-c="1D459" xlink:href="#MJX-558-TEX-I-1D459"></use></g></g></g><g data-mml-node="mo" transform="translate(8822.3,0)"><use data-c="2B" xlink:href="#MJX-558-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(9822.6,0)"><use data-c="1D70F" xlink:href="#MJX-558-TEX-I-1D70F"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mover><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo stretchy="false">^</mo></mover></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mo accent="false" stretchy="false">→</mo><mi>j</mi></mrow></msub><mo>&gt;</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mrow data-mjx-texclass="ORD"><mi>n</mi><mi>u</mi><mi>l</mi><mi>l</mi></mrow></msub><mo>+</mo><mi>τ</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">\hat{score}_{i \to j} > score_{null} + \tau</script><span>，这里的 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.17ex" height="1.005ex" role="img" focusable="false" viewBox="0 -431 517 444" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.029ex;"><defs><path id="MJX-559-TEX-I-1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D70F" xlink:href="#MJX-559-TEX-I-1D70F"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>τ</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">\tau</script><span> 是在dev set上选择的来最大化F1的。</span></p></li></ul><blockquote><p><span>博主：不理解怎么训练的！！！我也不知道！！！2024年8月14日 12:13:45</span></p></blockquote></li></ul></li><li><p><span style="color:blue; font-family:Whitney"><span>SWAG</span></span></p><ul><li><p><strong><span>S</span></strong><span>ituations </span><strong><span>W</span></strong><span>ith </span><strong><span>A</span></strong><span>dversarial </span><strong><span>G</span></strong><span>enerations. Given a sentence, the task is to choose the most plausible continuation among four choices.</span></p><p><span>具有对抗生成的场景。给定一个句子，任务是选择最可靠的连续对象（在4个选项中选1个）</span></p></li><li><p><span>Fine-tuning（微调）：</span></p><ul><li><p><span>构建4个输入序列，每个包括给定句子A和一个可能的连续的句子B的连结；</span></p></li><li><p><span>仅仅引入的对于特定任务的参数是一个向量，它与[CLS] token的点积表示 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.05ex;"><defs><path id="MJX-560-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-560-TEX-I-1D436"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi></math></mjx-assistive-mml></mjx-container><script type="math/tex">C</script><span> 表示了对于每个选项的分数，该分数由softmax层进行归一化；</span></p></li><li><p><span>超参数：batch_size = 16, learning_rate = 2e-5。</span></p></li></ul></li></ul><blockquote><p><strong><span>大佬关于BERT SWAG实操解释</span></strong></p><p><span style="color:black"><span>Let&#39;s assume your </span><span style="color:red"><span>batch size</span></span><span> is </span><code>8</code><span> and your </span><span style="color:red"><span>sequence length</span></span><span> is </span><code>128</code><span>. Each SWAG example has </span><code>4</code><span> entries, the correct one and 3 incorrect ones.</span></span></p><ul><li><p><span>Instead of your </span><code>input_fn</code><span> returning an </span><code>input_ids</code><span> of size </span><code>[128]</code><span>, it should return one of size </span><code>[4, 128]</code><span>. Same for mask and sequence ids. So for each example, you will generate the sequences </span><code>predicate ending0</code><span>, </span><code>predicate ending1</code><span>, </span><code>predicate ending2</code><span>, </span><code>predicate ending3</code><span>. Also return a label scalar which is in an integer in the range </span><code>[0, 3]</code><span> to indicate what the gold ending is.</span></p></li><li><p><span>After batching, your </span><code>model_fn</code><span> will get an input of shape </span><code>[8, 4, 128]</code><span>. Reshape these to </span><code>[32, 128]</code><span> before passing them into </span><code>BertModel</code><span>. i.e., BERT will consider all of these independently.</span></p></li><li><p><span>Compute the logits as in </span><code>run_classifier.py</code><span>, but your &quot;classifier layer&quot; will just be a vector of size </span><code>[768]</code><span> (or whatever your hidden size is).</span></p></li><li><p><span>Now you have a set of logits of size </span><code>[32]</code><span>. Re-shape these back into </span><code>[8, 4]</code><span> and then compute </span><code>tf.nn.log_softmax()</code><span> over the 4 ending for each example. Now you have log probabilities of shape </span><code>[8, 4]</code><span> over the 4 endings and a label tensor of shape </span><code>[8]</code><span>, so compute the loss exactly as you would for a classification problem.</span></p></li></ul><p><span>若不考虑原句选择4个选项的概率分布，即认为每句各自的4个选项间相互独立，则可以把SWAG任务看成是4N个独立的二分类任务，N为训练集大小。</span></p><p><span>若考虑原句选择4个选项的概率分布，则可将原句和4个选项生成的4个输入序列在一个batch里面作为BERT的输入（</span><span style="color:red"><span>BERT认为每个batch的样本无关</span></span><span>），在输出层可同时获得这4个输入序列对应的[CLS]的隐状态，选择4个选项的概率分布表示为：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n1480" cid="n1480" mdtype="math_block" data-math-tag-before="4" data-math-tag-after="5" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" width="full" style="min-width: 38.952ex; position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="2.262ex" role="img" focusable="false" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.566ex; min-width: 38.952ex;"><defs><path id="MJX-833-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-833-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-833-TEX-N-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path id="MJX-833-TEX-N-A0" d=""></path><path id="MJX-833-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-833-TEX-N-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path id="MJX-833-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-833-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-833-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-833-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path id="MJX-833-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-833-TEX-N-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path id="MJX-833-TEX-N-68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-833-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-833-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-833-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-833-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-833-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-833-TEX-N-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path id="MJX-833-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-833-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path id="MJX-833-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-833-TEX-N-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(0.019382,-0.019382) translate(0, -750)"><g data-mml-node="math"><g data-mml-node="mtable" transform="translate(2078,0) translate(-2078,0)"><g transform="translate(0 750) matrix(1 0 0 -1 0 0) scale(51.6)"><svg data-table="true" preserveAspectRatio="xMidYMid" viewBox="6530.3 -750 1 1000"><g transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mlabeledtr"><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="6C" xlink:href="#MJX-833-TEX-N-6C"></use><use data-c="6F" xlink:href="#MJX-833-TEX-N-6F" transform="translate(278,0)"></use><use data-c="67" xlink:href="#MJX-833-TEX-N-67" transform="translate(778,0)"></use></g><g data-mml-node="mtext" transform="translate(1278,0)"><use data-c="A0" xlink:href="#MJX-833-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(1528,0)"><use data-c="73" xlink:href="#MJX-833-TEX-N-73"></use><use data-c="6F" xlink:href="#MJX-833-TEX-N-6F" transform="translate(394,0)"></use><use data-c="66" xlink:href="#MJX-833-TEX-N-66" transform="translate(894,0)"></use><use data-c="74" xlink:href="#MJX-833-TEX-N-74" transform="translate(1200,0)"></use><use data-c="6D" xlink:href="#MJX-833-TEX-N-6D" transform="translate(1589,0)"></use><use data-c="61" xlink:href="#MJX-833-TEX-N-61" transform="translate(2422,0)"></use><use data-c="78" xlink:href="#MJX-833-TEX-N-78" transform="translate(2922,0)"></use></g><g data-mml-node="mo" transform="translate(4978,0)"><use data-c="28" xlink:href="#MJX-833-TEX-N-28"></use></g><g data-mml-node="mo" transform="translate(5367,0)"><use data-c="5B" xlink:href="#MJX-833-TEX-N-5B"></use></g><g data-mml-node="msub" transform="translate(5645,0)"><g data-mml-node="mi"><use data-c="68" xlink:href="#MJX-833-TEX-N-68"></use></g><g data-mml-node="mn" transform="translate(589,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-833-TEX-N-31"></use></g></g><g data-mml-node="mo" transform="translate(6637.6,0)"><use data-c="2C" xlink:href="#MJX-833-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(7082.2,0)"><g data-mml-node="mi"><use data-c="68" xlink:href="#MJX-833-TEX-N-68"></use></g><g data-mml-node="mn" transform="translate(589,-150) scale(0.707)"><use data-c="32" xlink:href="#MJX-833-TEX-N-32"></use></g></g><g data-mml-node="mo" transform="translate(8074.8,0)"><use data-c="2C" xlink:href="#MJX-833-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(8519.4,0)"><g data-mml-node="mi"><use data-c="68" xlink:href="#MJX-833-TEX-N-68"></use></g><g data-mml-node="mn" transform="translate(589,-150) scale(0.707)"><use data-c="33" xlink:href="#MJX-833-TEX-N-33"></use></g></g><g data-mml-node="mo" transform="translate(9512,0)"><use data-c="2C" xlink:href="#MJX-833-TEX-N-2C"></use></g><g data-mml-node="msub" transform="translate(9956.7,0)"><g data-mml-node="mi"><use data-c="68" xlink:href="#MJX-833-TEX-N-68"></use></g><g data-mml-node="mn" transform="translate(589,-150) scale(0.707)"><use data-c="34" xlink:href="#MJX-833-TEX-N-34"></use></g></g><g data-mml-node="mo" transform="translate(10949.2,0)"><use data-c="5D" xlink:href="#MJX-833-TEX-N-5D"></use></g><g data-mml-node="mo" transform="translate(11449.4,0)"><use data-c="22C5" xlink:href="#MJX-833-TEX-N-22C5"></use></g><g data-mml-node="mi" transform="translate(11949.7,0)"><use data-c="77" xlink:href="#MJX-833-TEX-N-77"></use></g><g data-mml-node="mo" transform="translate(12671.7,0)"><use data-c="29" xlink:href="#MJX-833-TEX-N-29"></use></g></g></g></g></g></svg><svg data-labels="true" preserveAspectRatio="xMaxYMid" viewBox="1278 -750 1 1000"><g data-labels="true" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="mtd" id="mjx-eqn:5"><g data-mml-node="mtext"><use data-c="28" xlink:href="#MJX-833-TEX-N-28"></use><use data-c="35" xlink:href="#MJX-833-TEX-N-35" transform="translate(389,0)"></use><use data-c="29" xlink:href="#MJX-833-TEX-N-29" transform="translate(889,0)"></use></g></g></g></svg></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd><mtext>(5)</mtext></mtd><mtd><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">log</mi><mtext>&nbsp;</mtext><mi data-mjx-auto-op="false">softmax</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><msub><mi mathvariant="normal">h</mi><mn>1</mn></msub><mo>,</mo><msub><mi mathvariant="normal">h</mi><mn>2</mn></msub><mo>,</mo><msub><mi mathvariant="normal">h</mi><mn>3</mn></msub><mo>,</mo><msub><mi mathvariant="normal">h</mi><mn>4</mn></msub><mo stretchy="false">]</mo><mo>⋅</mo><mi mathvariant="normal">w</mi><mo stretchy="false">)</mo></mrow></mtd></mlabeledtr></mtable></math></mjx-assistive-mml></mjx-container></div></div><p><span>Fine-tuning模型仅包含一个与输出层隐状态同维的向量 </span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="1.633ex" height="1ex" role="img" focusable="false" viewBox="0 -431 722 442" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-561-TEX-N-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="77" xlink:href="#MJX-561-TEX-N-77"></use></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">w</mi></mrow></math></mjx-assistive-mml></mjx-container><script type="math/tex">\mathrm{w}</script><span> 。</span></p></blockquote></li></ul><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>问题</span></kbd><span> 为什么输出层不用4*hidden_size维矩阵，而仅使用hidden_size维向量？</span></p><p><kbd style="background:yellow; color:red"><span>个人理解</span></kbd><span>：K分类任务输出层参数为K * hidden_size的矩阵，即输出层含K个神经元（参数维度hidden_size * K，其实只有K-1个自由神经元），而</span><span style="color:red"><span>SWAG本质是二分类任务</span></span><span>，从任务输出（</span><code>是</code><span> </span><code>否</code><span>是正确选项）也能看出，因此输出层用一个神经元即可。</span></p><h4 id='ablation-studies'><span>Ablation Studies</span></h4><blockquote><p><span>消融实验，理解模型参数。</span></p></blockquote><figure class='table-figure'><table><thead><tr><th style='text-align:center;' ><img src=".\pp003_files\image-20240814164046173.png" referrerpolicy="no-referrer" alt="image-20240814164046173"></th><th style='text-align:center;' ><img src=".\pp003_files\image-20240814164103277.png" referrerpolicy="no-referrer" alt="image-20240814164103277"></th><th style='text-align:center;' ><img src=".\pp003_files\image-20240814164118314.png" referrerpolicy="no-referrer" alt="image-20240814164118314"></th></tr></thead><tbody><tr><td style='text-align:center;' ><span style="color:red"><span>图5</span></span></td><td style='text-align:center;' ><span style="color:red"><span>图6</span></span></td><td style='text-align:center;' ><span style="color:red"><span>图7</span></span></td></tr></tbody></table></figure><ul><li><p><span>Effect of Pre-training Tasks</span></p><ul><li><p><span>使用相同的预训练数据、模型参数、微调参数等，评估深层双向网络的重要性。</span></p><p><span>Standard Left-to-Right LM(LTR). The addition of NSP task significantly improved the LTR model.</span></p></li><li><p><span>“No NSP”：不进行NSP任务，只进行Masked LM task；</span></p></li><li><p><span>“LTR &amp; No NSP”：不进行NSP任务，且使用标准语言模型采用的Left-to-Right训练方法。</span></p><p><span>各模型区别如</span><span style="color:red"><span>图5</span></span><span>所示。</span></p></li><li><p><span>如果采用像ELMo那样训练LTR和RTL模型，再对结果进行拼接，有以下缺点：</span></p><ul><li><p><span>相对于单个双向模型来说，表征长度翻倍，代价相对提高。</span></p></li><li><p><span>这种拼接不直观，因为对于QA任务来说，</span><span style="color:red"><span>RTL任务做的事实际上是“根据答案推导问题”</span></span><span>，这是不靠谱的。</span></p></li><li><p><span>与深度双向模型相比，这种在上下文上的双向交互的能力较弱，因为双向模型在每层都能进行双向的上下文交互。</span></p></li></ul></li></ul></li><li><p><span>Effect of Model Size</span></p><ul><li><p><span>有关模型大小的影响的实验；</span></p></li><li><p><span>我们用一个不同的层数、隐藏单元、以及注意力头数训练了许多BERT模型，而有时使用与前文描述相同的超参数和训练过程。</span></p></li><li><p><span>作者证明了：如果模型经过充分的预训练，即使模型尺寸扩展到很大，也能极大改进训练数据规模较小的下游任务。</span></p><p><span>各模型区别如</span><span style="color:red"><span>图6</span></span><span>所示。</span></p></li></ul></li><li><p><span>Feature-based Approach with BERT</span></p><ul><li><p><span>将BERT应用于Feature-based的方法</span></p><ul><li><p><span style="border-radius: 10px; border-top: 1px solid red; border-bottom: 1px solid red; border-left: 1px solid red; border-right: 1px solid red; background: yellow"><span>feature-based的方法是从预训练模型中提取固定的特征，不对具体任务进行微调</span></span><span>。这样的方法也有一定的优点：</span></p><p><kbd style="background:#f8e272"><span>1</span></kbd><span> 并非所有任务都能用Transformer架构简单表示，因此这些任务都需要添加特定的架构；</span></p><p><kbd style="background:#a8e195"><span>2</span></kbd><span> feature-based的方法还有一定的计算成本优势。</span></p></li><li><p><span>作者进行了如下实验：在CoNLL-2003数据集上完成NER任务，不适用CRF输出，而是从一到多个层中提取出激活值，输入到2层768维的BiLSTM中，再直接分类。</span></p></li></ul></li><li><p><span>某些下游任务可能无法表示成Transformer encoder架构，所以有必要考虑能够处理特定任务的预训练模型架构。此外，预先训练模型学习特征表示，之后直接用这些特征表示处理下游任务，计算代价更小。如拼接BERT的后四层作为token特征表示，NER任务的F1值仅比使用BERT fine-tuning低0.3。</span></p><p><span>各模型区别如</span><span style="color:red"><span>图7</span></span><span>所示。</span></p></li><li><p><span>结论说明：无论是否进行微调，BERT模型都是有效的。</span></p></li></ul></li></ul><p>&nbsp;</p><h3 id='结论和尾声'><span>结论和尾声</span></h3><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>博文2的作者</span></kbd></p><p><span>在本文发布的当时，语言模型迁移学习的经验改进表明，丰富的</span><span style="color:red"><span>无监督预训练</span></span><span>是许多</span><span style="color:#2196f3;font-weight:bold"><span>语言理解系统</span></span><span>的组成部分，这个效果是非常好的。</span></p><p><span style="border-bottom: 2px dashed FireBrick;"><span>使得训练集比较少的任务也能够使用深度神经网络，获得比较好的效果</span></span><span>。</span></p><p><span>特别是，这些结果使</span><span style="color:red"><span>低资源任务</span></span><span>也能从</span><span style="color:#2196f3;font-weight:bold"><span>深度</span><span style="text-decoration: underline 1px solid red; text-decoration-style: single"><span>单向</span></span><span>架构</span></span><span>中受益。BERT的主要贡献是进一步将这些发现</span><span style="color:#2196f3;font-weight:bold"><span>推广到深度</span><span style="text-decoration: underline 1px solid red; text-decoration-style: double"><span>双向</span></span><span>架构</span></span><span>，允许相同的预训练模型成功地处理广泛的NLP任务。</span></p><p><kbd style="border:1px dotted #990000; font-size:20px; color: red; font-family: comic sans ms, 微软雅黑; font-weight:bold"><span>博文4的作者</span></kbd></p><p><span>个人认为BERT的意义在于：</span></p><ul><li><p><span>成功实践了pre-training + fine-tuning的深度学习范式；</span></p></li><li><p><span>发掘了在NLP中“深度双向架构”在预训练任务中的重要意义。</span></p></li></ul><p>&nbsp;</p><h2 id='参考博文'><span>参考博文</span></h2><ol start='' ><li><p><a href='https://cloud.tencent.com/developer/article/1546078'><span>论文解读 | BERT详解：开创性自然语言处理框架的全面指南</span></a></p></li><li><p><a href='https://juejin.cn/post/7235142303274025017'><span>2023了，再来看看NLP经典之作 - BERT丨论文解读</span></a></p></li><li><p><a href='https://blog.csdn.net/sinat_34072381/article/details/105959774'><span>【论文解读】BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span></a></p><ol start='' ><li><p><a href='https://arxiv.org/abs/1810.04805'><span>论文原文链接</span></a></p></li><li><p><a href='https://github.com/google-research/bert/issues/38'><span>plan to release SWAG code?</span></a></p></li></ol></li><li><p><a href='https://blog.csdn.net/qq_43586043/article/details/119574579'><span>BERT 论文解读</span></a></p></li><li><p><a href='https://cloud.baidu.com/article/1878177'><span>BERT：论文解读的利器与展望</span></a><span> - 短文</span></p></li></ol><p>&nbsp;</p><h2 id='博文目录'><span>博文目录</span></h2><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n796"><a class="md-toc-inner" href="#bert---论文精读学习笔记">BERT - 论文精读学习笔记</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n810"><a class="md-toc-inner" href="#预备知识">预备知识</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n859"><a class="md-toc-inner" href="#梗概">梗概</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n892"><a class="md-toc-inner" href="#简介">简介</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n940"><a class="md-toc-inner" href="#摘要">摘要</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n952"><a class="md-toc-inner" href="#预训练模型pre-trained-model）">预训练模型（Pre-trained Model）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n953"><a class="md-toc-inner" href="#无监督基于特征的方法unsupervised-feature-based-approaches）">无监督基于特征的方法（Unsupervised Feature-based Approaches）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n969"><a class="md-toc-inner" href="#无监督微调方法unsupervised-fine-tuning-approaches）">无监督微调方法（Unsupervised Fine-tuning Approaches）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n987"><a class="md-toc-inner" href="#从监督数据迁移学习transfer-learning-from-supervised-data）">从监督数据迁移学习（Transfer Learning From Supervised Data）</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n993"><a class="md-toc-inner" href="#bert预训练">BERT预训练</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1055"><a class="md-toc-inner" href="#bert预训练和微调">BERT预训练和微调</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1084"><a class="md-toc-inner" href="#深入bert模型">深入BERT模型</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1125"><a class="md-toc-inner" href="#bert模型可学习参数计算">BERT模型可学习参数计算</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1131"><a class="md-toc-inner" href="#bert-输入--输出">BERT <code>输入</code> &amp; <code>输出</code></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1153"><a class="md-toc-inner" href="#切词方法wordpiece">切词方法：WordPiece</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1161"><a class="md-toc-inner" href="#合并句子的方法">合并句子的方法：</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1203"><a class="md-toc-inner" href="#mlm预训练的细节">MLM预训练的细节</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1209"><a class="md-toc-inner" href="#任务1完形填空masked-lm-mlm）">任务1：完形填空（Masked LM, MLM）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1281"><a class="md-toc-inner" href="#任务2句子匹配next-sentence-prediction-nsp）">任务2：句子匹配（Next Sentence Prediction, NSP）</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1340"><a class="md-toc-inner" href="#再看微调">再看微调</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1383"><a class="md-toc-inner" href="#实验">实验</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n1484"><a class="md-toc-inner" href="#ablation-studies">Ablation Studies</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n1545"><a class="md-toc-inner" href="#结论和尾声">结论和尾声</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1558"><a class="md-toc-inner" href="#参考博文">参考博文</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1576"><a class="md-toc-inner" href="#博文目录">博文目录</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n1578"><a class="md-toc-inner" href="#原文目录">原文目录</a></span></p></div><h2 id='原文目录'><span>原文目录</span></h2><p><span>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span>
<span>1 Introduction</span>
<span>2 Related Work</span>
<span>	</span><span>2.1 Unsupervised Feature-based Approaches</span>
<span>	</span><span>2.2 Unsupervised Fine-tuning Approaches</span>
<span>	</span><span>2.3 Transfer Learning from Supervised Data</span>
<span>3 BERT</span>
<span>	</span><span>3.1 Pre-training BERT</span>
<span>	</span><span>3.2 Fine-tuning BERT</span>
<span>4 Experiments</span>
<span>	</span><span>4.1 GLUE</span>
<span>	</span><span>4.2 SQuAD v1.1</span>
<span>	</span><span>4.3 SQuAD v2.0</span>
<span>	</span><span>4.4 SWAG</span>
<span>5 Ablation Studies</span>
<span>	</span><span>5.1 Effect of Pre-training Tasks</span>
<span>	</span><span>5.2 Effect of Model Size</span>
<span>	</span><span>5.3 Feature-based Approach with BERT</span>
<span>6 Conclusion</span>
<span>References</span></p><p>&nbsp;</p><p>&nbsp;</p><p><kbd style="border:1px double black; font-size:20px; color: #990000; font-family: comic sans ms, 微软雅黑; font-weight:bold; border-bottom: 2px solid black; border-top: 2px solid black;"><span>博文免责声明</span></kbd></p><ol start='' ><li><p><span>本条博文信息主要整合自网络，部分内容为自己的理解写出来的，如有断章截句导致不正确或因个人水平有限未能详尽正确描述的地方，敬请各位读者指正；</span></p></li><li><p><span>引用出处可能没有完全追溯到原始来源，如因此冒犯到原创作者，请</span><a href='https://mustbook.github.io/'><span>联系本人</span></a><span>更正/删除；</span></p></li><li><p><span>博文的发布主要用于自我学习，其次希望帮助到有共同疑惑的朋友。</span></p></li></ol><div style="
    border-radius: 25px; 
    border: 2px solid #990000;
    background: #990000;
    padding: 20px;
"><center><span style="color:white">欢迎随时联系讨论，一起成长进步。</span></center></div><p>&nbsp;</p></div></div>
<a href=".typora-export-content" id="scroll-up" style="display: block;">
		<i class="material-icons md-20 md-middle"></i>
	</a></body>
</html>